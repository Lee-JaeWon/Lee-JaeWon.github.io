---
title : "[논문 리뷰] TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering"
category :
    - 3d_reconstruction
tag :
    - 3d_reconstruction
toc : true
toc_sticky: true
comments: true
sidebar_main: true
---
[2024,Arxiv] TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering 논문 리뷰

<br>

# Introduction
point based radiance field rendering은 novel view synthesis라는 분야에 있어 좋은 성능을 보여오고 있다.

하지만 이러한 연구의 최신 방식인 **3D Gaussian Splatting**은 blurring과 cloudy artifact들로 인해 아주 디테일한 scene을 rendering하는데 어려움을 겪는다.

반면 **ADOP**는 더 선명한 이미지를 수용할 수 있지만 neural reconstruction network는 성능을 저하시키고,시간적인 불안정성과 point cloud와의 큰 gap에 효과적으로 대응하지 못한다.

이러한 문제들을 해결하고, 이 3DGS와 ADOP의 **강점을 활용**하기 위해 제안한 것이 본 논문(TRIPS)이다.

**TRIPS**는 3DGS처럼 다양한 크기의 splat을 rasterize하고, ADOP처럼 reconstruction network를 적용하여 구멍이 없고 선명한 이미지를 생성한다.

이외에도 논문 제목에서 보이는 **Trilinear**관련 및 **image pyramid**에 관한 사항을 사용한 것 같다.

(뒤에서 살펴보자)

본 논문에서 주장하는 기여는 다음과 같다.

- radiance field rendering을 위한 **novel trilinear point splatting** 기술의 소개
- 점 위치 및 크기를 포함하는 모든 입력 parameter를 최적화하여 robust scene representation

<br>

# Method
<p align="center"><img src="/MyPDF/trips(1).png" width = "800" ></p>

Fig2. 에서 전체 파이프라인을 확인할 수 있으며, input 데이터는 3DGS와 비슷하게 image, camera parameters, dense point cloud이다.

이제 다만 초기 3DGS와 달리 initial point cloud에 관한 소개가 자유로워진 것 같다.(LiDAR 혹은 stereo 같은 방법으로 얻을 수 있다고 소개한다.)

본 논문의 핵심 내용은 **Trilinear point renderer**이다.

<br>

## Differentiable Trilinear Point Splatting
<p align="center"><img src="/MyPDF/trips(2).png" width = "500" ></p>

Fig3.이 Trilinear point splatting에 관한 전 과정이다.

먼저 camera extrinsic/intrinsic parameter를 사용하여 각각의 world coordinate의 한 점을 screen space의 한 점과 size로 가져올 수 있다.(projection)

$ s = f*s_w / z $

이렇게 screen space로 가져와진 size($s$)를 토대로 trilinear형태를 만들기 위한 작업을 한다.

$log(s)$를 토대로 **어떤 layer 사이에 들어갈 것인지 결정**하고, point를 $2 \times 2 \times 2$ splat으로 bilinearly하게 피라미드에 넣는 것 같다.(이미지보고 이해하면 좋을 것 같다.) 

그리고 원래 이러한 trilinear한 구조가 적용된 opacity(final opacity value)가 결정되야하기 때문에, x,y bilinear와 layer간 linear weight를 활용하여 final opacity value를 결정한다.($\gamma$가 최종)

<p align="center"><img src="/MyPDF/trips(3).png" width = "500" ></p>

## Multi Resolution Alpha Blending
이제 이러한 피라미드 픽셀에 한 픽셀만 저장되는 것이 **아닌** multiple points가 **같은 픽셀에 저장될 수 있다.** 이를 위해 list를 생성하고 depth를 기준으로 정렬된 리스트를 만든다.

<p align="center"><img src="/MyPDF/trips(4).png" width = "500" ></p>

여기서 **front-to-back alpha blending**을 수행한다.

즉 이제 어떠한 ray상에서의 opacity를 summation하는 구조가 **아닌**

피라미드로 구조를 옮겼기 때문에 다음과 같이 **리스트를 제작**하고 정렬된 depth와 그 때의 alpha를 이용하여 alpha blending을 수행한다고 이해하면 된다.

식은 기존의 식들과 동일한 것 같다.

<p align="center"><img src="/MyPDF/trips(5).png" width = "500" ></p>

## Neural Network
이러한 본 논문의 renderer의 결과는 feature image pyramid이다.(n layer로 구성된)

이러한 개별 layer가 최종적으로 아래 그림과 같이 compact neural network를 통해 single full-resolution image로 통합된다.

<p align="center"><img src="/MyPDF/trips(6).png" width = "600" ></p>

single gated convolution이 사용되었다고 한다.

<p align="center"><img src="/MyPDF/trips(7).png" width = "600" ></p>

결국 renderer를 통해 얻은 image feature pyramid를 이용해 high-resolution image를 만드는데 neural network를 사용하여 통합하는 것을 설명한다.

이 과정에서 network의 주요 task는 holl-filling과 outlier removal를 수행한다고 한다.

Neural Network은 이 정도의 아이디어만 이해하고 넘어가겠다.

## Spherical Harmonics Module and Tone Mapping
<p align="center"><img src="/MyPDF/trips(8).png" width = "600" ></p>

view dependent함이나 특정한 capture parameter를 모델링하기 위해 network출력을 SH계수로 선택적으로 해석한다고 한다.(그 다음 SH -> RGB)

그 다음 추가적인 Tone mapping기를 사용해서 노출 시간, white balance 등등을 모델링 했다고 하는데, 이것은 다른 연구에서 가져온 것이라 자세히 가지는 않았다. 

# Evaluation 및 고찰
<p align="center"><img src="/MyPDF/trips(9).png" width = "800" ></p>

성능 자체는 모든 방면에서 SOTA를 능가하지는 않는 것을 보이지만,

screen-space image pyramid 구조를 통한 효율적인 rasterize를 제시한 것에 큰 어필을 하는 것 같다.

PSNR싸움보다 LPIPS 싸움에서 큰 성능향상을 이룬 것 같다.

노이즈 관련해서도 좋은 모습을 보인 것 같다.

<br>

# 참고자료
[Franke, Linus, et al. "TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering." arXiv preprint arXiv:2401.06003 (2024).](https://arxiv.org/abs/2401.06003)

📣<br>
포스팅에서 오류나 궁금한 점은 Comments를 작성해 주시면, 많은 도움이 됩니다.💡
{: .notice--info}