---
title : "[ë…¼ë¬¸ ë¦¬ë·°] LCDNet: Deep Loop Closure Detection and Point Cloud Registration for LiDAR SLAM"
category :
    - SLAM
tag :
    - SLAM
toc : true
toc_sticky: true
comments: true
sidebar_main: true
---
[IEEE T-RO,2022] LCDNet: Deep Loop Closure Detection and Point Cloud Registration for LiDAR SLAM ë…¼ë¬¸ ë¦¬ë·°

# Abstract
**Loop closure detection**ì€ SLAMì—ì„œ essentialí•œ ìš”ì†Œì´ë©°, ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ëˆ„ì ë˜ëŠ” ì˜¤ì°¨(drift error)ë¥¼ ì¤„ì´ëŠ”ë° ë„ì›€ì´ ëœë‹¤.

ìµœê·¼ ëª‡ ë…„ê°„, ì—¬ëŸ¬ deep learning ë°©ì‹ì´ loop closure detectionì—ì„œ ìˆ˜ì‘ì—…ë§Œí¼ **íš¨ê³¼ì ì´ì§€ ëª»í–ˆë‹¤.**

íŠ¹íˆ reverse loopì—ì„œ ë”ìš± ê·¸ë ‡ë‹¤ê³  í•œë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **LCDNet**ì´ë¼ê³  í•˜ëŠ” ìƒˆë¡œìš´ ë”¥ëŸ¬ë‹ ì ‘ê·¼ë²•ì„ ì†Œê°œí•œë‹¤.

ë‹ˆ ì ‘ê·¼ë²•ì€ ì´ì „ì— ë°©ë¬¸í•œ ì¥ì†Œë¥¼ detectioní•˜ê³ , í˜„ì¬ scanê³¼ mapì‚¬ì´ì˜ 6DOF relative transformationì„ ì¶”ì •í•˜ë©°

LiDAR point cloudì˜ loop closureë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¸ì‹í•œë‹¤.

LCDNetì€ ë‹¤ìŒ êµ¬ì„± ìš”ì†Œë¡œ ì´ë£¨ì–´ì ¸ìˆë‹¤.

- Shared encoder
- Place recognition head : extract global descriptor
- relative pose head : ë‘ point cloudê°„ transformation ì¶”ì •

**end-to-end training**ì´ ê°€ëŠ¥í•˜ë‹¤ê³  í•œë‹¤.

ì—¬ëŸ¬ ììœ¨ ì£¼í–‰ ë°ì´í„° ì…‹ì—ì„œ í‰ê°€í–ˆì„ ë•Œ, SOTAë¥¼ ë‹¬ì„±í–ˆë‹¤ê³  í•œë‹¤.

# Introduction

**typical SLAM pipeline**ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤.

- 1) consecutive scan allignment
- 2) loop detection
- 3) loop closure to align the current scan to the previously visited place : ì´ì „ ë°©ë¬¸ ì¥ì†Œì™€ í˜„ì¬ scanê³¼ì˜ alignì„ í†µí•œ map correction.

2) 3) ê³¼ì •ì€ loopê°€ ê°ì§€ë˜ì—ˆì„ ë•Œ, pose graphì— constraintë¡œ ë„£ì–´ì£¼ë©° accumulated driftë¥¼ ê°ì†Œì‹œí‚¨ë‹¤.

loop detectionë¥¼ ìœ„í•´ local keypointë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜ global handcrafted descriptorë¥¼ í™œìš©í•˜ëŠ”ë°,

ì´ëŸ¬í•œ ì ‘ê·¼ë²•ì˜ ëŒ€ë¶€ë¶„ì€ ë‘ point cloudë¥¼ ë¹„êµí•˜ê¸° ìœ„í•´ ìƒí™©ì— ë§ëŠ” 'ì„ì˜ì˜' í•¨ìˆ˜ë¥¼ í•„ìš”ë¡œ í•˜ë©°, ê³¼ê±° scan ìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡ runtimeì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤.

ì´ë¥¼ ìœ„í•´ loop detection taskì— **DNN(Deep neural network)ë¥¼ ì ìš©í•œ ì—°êµ¬**ë“¤ ë˜í•œ ë“±ì¥í•˜ì˜€ë‹¤.

**DNN ê¸°ë°˜ ë°©ì‹**ì€ handcrafted method(ìˆ˜ì‘ì—…)ë³´ë‹¤ ë¹¨ë¼ì„œ loop closure detectionì„ ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ì„±ëŠ¥ì€ SOTAë§Œí¼ ë‚˜ì˜¤ì§€ ì•Šì•˜ë‹¤.

Point cloud registrationì„ ìœ„í•´ ICPë¥¼ ì„¤ëª…í•˜ëŠ”ë°, ìœ„ì¹˜ë‚˜ ë°©í–¥ì— í° ì°¨ì´ê°€ ìˆìœ¼ë©´ ì •ë ¬í•˜ì§€ ëª»í•˜ê±°ë‚˜ local minimaì— ë¹ ì§ˆ ìˆ˜ ìˆë‹¤ê³  ì„¤ëª…í•œë‹¤.

ì´ëŸ¬í•œ typical SLAM pipelineì— ëŒ€í•´, ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **LCDNet**ì„ ì œì•ˆí•˜ì˜€ë‹¤ê³  í•œë‹¤. ([Figure 1](../../MyPDF/lcdnet(1).png))

<p align="center"><img src="/MyPDF/lcdnet(1).png" width = "700" ></p>
<p align="center">Figure 1</p>

loop detectionê³¼ point cloud registrationì„ ìˆ˜í–‰í•œë‹¤.

LCDNetì€ DNNì´ distinctive featureë¥¼ ì¶”ì¶œí•˜ëŠ” ê¸°ëŠ¥ê³¼ feature matchingì„ ìœ„í•œ transport theoryì˜ ì•Œê³ ë¦¬ì¦˜ì„ **ê²°í•©**í•œë‹¤.

LCDNetì€ **shared backbone**ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, abstractì—ì„œ ì„¤ëª…í•œ ê²ƒì²˜ëŸ¼ **Place recognition head(extract global descriptor)**ì™€ **relative pose head**ë¡œ êµ¬ì„±ëœë‹¤.

ë˜í•œ LCDNetì˜ í•µì‹¬ ìš”ì†Œ ì¤‘ í•˜ë‚˜ëŠ” **unbalanced optimal transport(UOT)** algorithmì´ë©°, ë¯¸ë¶„ ê°€ëŠ¥í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í–ˆë‹¤ê³  í•œë‹¤.

UOTëŠ” íš¨ê³¼ì ì¸ feature matching, outlierì œê±°, ê°€ë ¤ì§„ ì§€ì  ì²˜ë¦¬(handle occluded points)ê°€ ê°€ëŠ¥í•˜ë©´ì„œë„ networkë¥¼ **end-to-end**ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.

ê·¸ë¦¬ê³  ê¸°ì¡´ existing loop closure ë°©ë²•ì€ relative **yaw** rotationë§Œ ì¶”ì •í–ˆë‹¤.(between two point clouds)

í•˜ì§€ë§Œ LCDNetì€ **6DoF**ë¥¼ ëª¨ë‘ ì¶”ì •í•œë‹¤. ì´ëŠ” subsequent ICP refinementë¥¼ ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

# Technical Approach

<p align="center"><img src="/MyPDF/lcdnet(2).png" width = "700" ></p>
<p align="center">Figure 2</p>

[Figure 2](../../MyPDF/lcdnet(2).png)ì—ì„œ overviewë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

## Feature Extraction
<p align="center"><img src="/MyPDF/lcdnet(3).png" width = "700" ></p>
<p align="center">Figure 3</p>

feature extractor streamì€ 3D Object detectionì„ ìœ„í•´ ì œì•ˆëœ **pointvoxel-RCNN(PV-RCNN)**ì„ ê¸°ë°˜ìœ¼ë¡œ ì œì‘í•˜ì˜€ë‹¤.

PV-RCNNì€ voxel-based methodì˜ ê¸°ëŠ¥ê³¼(high-level feature extract) PointNet type(fine-grained feature extract) ì•„í‚¤í…ì³ë¥¼ ê²°í•©í•˜ì˜€ë‹¤.<br>
(ë³µì…€ ê¸°ë°˜ì€ ë†’ì€ ìˆ˜ì¤€ì„ ì¶”ì¶œí•˜ì§€ë§Œ, ì„¸ë¶€ ì‚¬í•­ì„ ë†“ì¹  ìˆ˜ ìˆê³ , PointNetì€ ì„¸ë¶€ ì‚¬í•­ captureëŠ” ì¢‹ì§€ë§Œ ë†’ì€ ìˆ˜ì¤€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ë°ëŠ” íš¨ê³¼ì ì´ì§€ ì•Šì•„ ì´ ë‘˜ì„ ê²°í•©í•œ ë°©ì‹ì´ë¼ê³  í•œë‹¤.)

ì—¬ê¸°ì„œ object detectionì´ ì•„ë‹ˆë¼ feature extractionë§Œ ê´€ì‹¬ìˆê¸° ë•Œë¬¸ì—

ì˜¤ì§, 3D voxel DNNê³¼ Voxel set abstraction(VSA) moduleë§Œ ì‚¬ìš©í•˜ê³ ,

region proposal, ROI-grid pooling, FC layer ë“±ì€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤.

---

3D Voxel DNNì„ ì‚¬ìš©í•˜ì—¬ ì²« ë²ˆì§¸ë¡œ point cloudë¥¼ **voxel gridë¡œ ë³€í™˜**í•œë‹¤.

ì—¬ê¸°ì„œ voxel featureëŠ” ë™ì¼í•œ voxelë‚´ì— ìˆëŠ” ëª¨ë“  ì ì— ê±¸ì³ í‰ê· í™”ëœë‹¤.

ì´ì–´ì„œ, sparse 3D convolutionê³¼ downsamplingì„ ì‚¬ìš©í•˜ì—¬ feature pyramidë¥¼ ì¶”ì¶œí•œë‹¤.

4ê°œì˜ pyramid blockìœ¼ë¡œ êµ¬ì„±ë˜ë©°, down sampling ratesê°€ 1, 2, 4, 8ë°°ì¸ sparse 3D convolutionìœ¼ë¡œ êµ¬ì„±ëœë‹¤ê³  í•œë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ, Zì¶•ì„ ë”°ë¼ íŠ¹ì§•ì„ ìŒ“ì•„ ê°€ì¥ ì¡°ë°€í•œ feature mapì„ 2D BEV(Bird-Eye-View?) ë§µìœ¼ë¡œ ë³€í™˜í•œë‹¤.

(ë³µì¡í•´ì„œ ë” ê¹Šê²Œ ì´í•´í•˜ì§€ëŠ” ì•Šì•˜ëŠ”ë°, ê²°êµ­ 3D Voxel DNNì„ ì‚¬ìš©í•˜ì—¬ voxel gridë¡œ ë³€í™˜í•˜ê³  feature pyramidë¥¼ ì¶”ì¶œí•˜ëŠ” ê³¼ì •ì´ë‹¤ ì •ë„ë¡œ ì´í•´í–ˆë‹¤.)

<p align="center"><img src="/MyPDF/lcdnet(4).png" width = "700" ></p>
ì¶œì²˜ : [ë…¼ë¬¸ë¦¬ë·° PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection](https://donologue.tistory.com/389)

---
VSA ëª¨ë“ˆì€ pyramid feature mapë“¤ê³¼ BEV feature map ê·¸ë¦¬ê³  input point cloudë¥¼ Nê°œì˜ ì£¼ìš” keypoint featureë¡œ ì§‘ê³„í•œë‹¤.

ì´ë¥¼ ìœ„í•´ Farthest point sampling(FPS)ë¥¼ ì‚¬ìš©í•´ input point cloudë¥¼ downsamplingí•œë‹¤.<br>
(ê· ì¼í•˜ê²Œ ë¶„í¬ëœ Nê°œì˜ keypoint ì„ íƒ)

VSA ëª¨ë“ˆì€ SA(Set Abstraction)ì˜ extensionì´ë‹¤.([ì°¸ê³ ](https://lee-jaewon.github.io/deep_learning_study/pointnet_pp/#32-hierarchical-point-set-feature-learning))

SAëŠ” raw point cloudì—ì„œ ë™ì‘í•˜ê³ , VSAëŠ” 3D sparse feature mapì—ì„œ voxel featureë¥¼ ì´ì›ƒí•œë‹¤.

keypoint featureëŠ” MLPë¥¼ í™œìš©í•˜ì—¬ ì¶”ì¶œëœë‹¤.(ë…¼ë¬¸ ì‹ ì°¸ê³ )

ì´ëŸ¬í•œ feature extractorê°€ SOTAì¸ ê²ƒë„ í™•ì¸í–ˆë‹¤ê³  í•œë‹¤.

## Global Descriptor
ê°„ë‹¨í•˜ê²Œ point cloudì˜ global descriptorëŠ” **NetVLAD layer**ë¥¼ ì‚¬ìš©í•˜ì—¬ keypointì˜ feature setì„ compact G-dimesional vectorë¡œ ì§‘ê³„í•˜ì—¬ ìƒì„±í•œë‹¤.

NetVlad ë ˆì´ì–´ëŠ” PointNetì—ì„œ ì‚¬ìš©ë˜ëŠ” max pooling ëŒ€ì‹  ì‚¬ìš©ëœë‹¤.

ğŸ¦¾**í•œ ì¤„ ì •ë¦¬**<br>
Place recognitionì„ ìœ„í•´ ì‚¬ìš©ë˜ëŠ” NetVLADë¥¼ ì´ìš©í•˜ì—¬ Feature Extraction moduleì—ì„œ ìƒì„±í•œ point cloudì˜ feature setì— ëŒ€í•´ global descriptorë¥¼ ì¶”ì¶œí•œë‹¤.<br>
ìì„¸í•œ ë‚´ìš©ì€ ë…¼ë¬¸ì„ ë” ì°¸ê³ í•´ì•¼í•  ê²ƒ ê°™ë‹¤.
{: .notice--info}

## Relative Pose Estimation
two point cloud $P$ì™€ $S$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ,

ë³¸ ë…¼ë¬¸ì˜ ì•„í‚¤í…ì³ì—ì„œ ì„¸ ë²ˆì§¸ ìš”ì†Œ(ëª¨ë“ˆ)ì€ 6DoF transformationì„ ì¶”ì •í•œë‹¤.

ì´ëŠ” source point cloud $P$ê³¼ target point cloud $S$ë¥¼ aligní•˜ê¸° ìœ„í•´ì„œì´ë‹¤.

ì´ taskë¥¼ feature extractorë¥¼ í†µí•´ ê³„ì‚°í•œ keypointì˜ featureë¥¼ ë§¤ì¹­í•˜ëŠ” ê²ƒìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤.<br>
([Figure 2](../../MyPDF/lcdnet(2).png) ì°¸ê³ )

LiDAR point cloudì˜ í¬ì†Œì„±ê³¼ feature extractorì—ì„œ ìˆ˜í–‰ë˜ëŠ” keypoint ìƒ˜í”Œë§ ë‹¨ê³„ë¡œ ì¸í•´, Pì˜ í¬ì¸íŠ¸ëŠ” Sì—ì„œ í•˜ë‚˜ì˜ ë§¤ì¹­ í¬ì¸íŠ¸ê°€ ì—†ì„ ìˆ˜ ìˆì§€ë§Œ, Sì—ì„œ ë‘˜ ì´ìƒì˜ í¬ì¸íŠ¸ ì‚¬ì´ì— ë†“ì¼ ìˆ˜ ìˆë‹¤.

ê·¸ë˜ì„œ ì´ taskì—ì„œ ì¼ëŒ€ì¼ ë§¤í•‘ì€ ì ì ˆí•˜ì§€ ì•Šë‹¤.

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, Sinkhorn algorithmì„ ì ìš©í–ˆë‹¤ê³  í•˜ë©°, ì´ëŠ” optimal transport theoryë¥¼ ë¹ ë¥´ê²Œ ì¶”ì •í•  ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.

ì´ ì ‘ê·¼ ë°©ì‹ì€ ë‘ point cloud ê°„ì˜ ë‹¤ëŒ€ì¼ ë§¤í•‘ì´ ê°€ëŠ¥í•œ unbalanced optimal transport(UOT)ì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„ëœë‹¤.

ì´ëŸ¬í•œ ë°©ì‹ì´ ìµœê·¼ ì—¬ëŸ¬ ì‘ì—…ì—ì„œ ì¢‹ì€ ëª¨ìŠµì„ ë³´ì˜€ë‹¤ê³  í•œë‹¤.

ì´ëŸ¬í•œ ì‹(OT)ë¥¼ UOTë¡œ ë°”ê¾¸ëŠ” ê²ƒê³¼ ì´ìœ ëŠ” ë…¼ë¬¸ì„ ë” ìì„¸íˆ ì°¸ê³ í•´ì•¼í•  ê²ƒ ê°™ë‹¤.<br>
(ì´í•´ê°€ ì•ˆê°€ì„œ ë„˜ì–´ê°.)

ì´í›„ ì¶”ì •í•œ UOTëŠ” point cloudê°„ correspondenceë¥¼ í‘œí˜„í•˜ê³ , Pì—ì„œ Së¡œ íˆ¬ì˜ëœ ëª¨ë“  í‚¤í¬ì¸íŠ¸ì˜ ì¢Œí‘œë¥¼ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©í•œë‹¤.

ì´í›„ weighted SVDë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ í¬ì¸íŠ¸ í´ë¼ìš°ë“œê°„ì˜ transformationì„ ì¶”ì •í•œë‹¤.

ğŸ¦¾**í•œ ì¤„ ì •ë¦¬**<br>
ê²°êµ­ Pì˜ ií¬ì¸íŠ¸ì™€ Sì˜ jí¬ì¸íŠ¸ì˜ ë§¤ì¹­ì˜ Costë¥¼ minimizeí•˜ê³ ì í•˜ê³  (matching -> relative pose), ì´ê±¸ ë‹¤ëŒ€ì¼ ë§¤í•‘ê³¼ ì„±ëŠ¥ì„ ìœ„í•´ UOTë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì„ ì„¤ëª…í•œë‹¤. ì´í›„ SVDë¥¼ ì‚¬ìš©í•˜ì—¬ transformationì„ ì¶”ì •í•œë‹¤.
{: .notice--info}

## Loss Function
ë„˜ì–´ê°€ë„ë¡ í•˜ê² ë‹¤.

## SLAM System
ìµœê·¼ì— ì œì•ˆëœ SLAM ì‹œìŠ¤í…œì¸ LIO-SAMì— ë³¸ ë…¼ë¬¸ì´ ì œì•ˆí•œ LCDNetì„ í†µí•©í•œë‹¤ê³  ì†Œê°œí•œë‹¤.

LIO-SAMì€ factor graphì—ì„œ êµ¬ì¶•ëœ LiDAR inertial odometry frameworkì´ë‹¤.

LIO-SAMì˜ ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ ê¸°ë°˜ loop closure ê°ì§€ë¥¼ LCDNetìœ¼ë¡œ ëŒ€ì²´í–ˆë‹¤.


# ì°¸ê³  ìë£Œ

- [Cattaneo, Daniele, Matteo Vaghi, and Abhinav Valada. "Lcdnet: Deep loop closure detection and point cloud registration for lidar slam." IEEE Transactions on Robotics 38.4 (2022): 2074-2093.](https://arxiv.org/abs/2103.05056)
- [https://github.com/robot-learning-freiburg/LCDNet](https://github.com/robot-learning-freiburg/LCDNet)
- [ë…¼ë¬¸ë¦¬ë·° PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection](https://donologue.tistory.com/389)
- [[ë…¼ë¬¸ ë¦¬ë·°] PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space](https://lee-jaewon.github.io/deep_learning_study/pointnet_pp/)

ğŸ“£<br>
í¬ìŠ¤íŒ…ì—ì„œ ì˜¤ë¥˜ë‚˜ ê¶ê¸ˆí•œ ì ì€ Commentsë¥¼ ì‘ì„±í•´ ì£¼ì‹œë©´, ë§ì€ ë„ì›€ì´ ë©ë‹ˆë‹¤.ğŸ’¡
{: .notice--info}