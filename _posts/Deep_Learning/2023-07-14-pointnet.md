---
title : "PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation 리뷰"
category :
    - Deep_Learning_Study
tag :
    - Deep_Learning
toc : true
toc_sticky: true
comments: true
sidebar_main: true
---
PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation 리뷰

# Abstract
Point cloud는 기하학적 데이터 구조(geometric data structure)의 중요한 유형이다.<br><br>
하지만 이것의 불규칙적인 형식으로 인해 대부분의 연구자들은 데이터를 균일한 3D voxel grid 혹은 이미지의 모음으로 바꾼다.<br><br>
하지만 이것도 불필요하게 큰 용량(voluminous)으로 렌더링되고 문제가 발생한다.<br><br>
**본 논문에서는** point cloud를 직접 사용한 새로운 유형의 neural network를 디자인하였다.<br>
이것은 입력의 점들에 대해 **permutation invariance**하다.<br>
(permutation invariant란 입력 벡터 요소의 순서와 상관없이 같은 출력을 생성하는 모델을 말합니다.<br>
[출처] 머신 러닝에서 permutation invariant의 의미|작성자 예비개발자)<br><br>
**PointNet** network는 객체 분류, 부분 segmentation, scene semantic parsing에 이르는 다양한 어플리케이션을 위한 통합 아키텍쳐를 제공한다고 한다.<br>
단순하지만 매우 효율적이고 효과적이라한다.<br><br>
<p align="center"><img src="/MyPDF/PN(1).png" width = "500" ></p>

# Introduction
전형적인 convolutional architecture들은 image grids나 3D voxel과 같은 highly regular input data를 요구한다.(가중치 공유 및 기타 커널 최적화를 수행을 위해)<br><br>
Abstract에서 말한 것처럼 point cloud는 regular한 format이 아니기 때문에 대부분의 연구자들이 deep net에 넣기 위해 다른 타입으로의 변환을 수행했었다.<br>
하지만 이렇게 처리하는 것은 불필요하게 큰 렌더링 데이터를 다루거나 데이터의 natural invariance를 가릴 수 있는 quantizaiton artifact를 발생 시킬 수 있다.<br><br>
다음과 같은 이유들로 본 논문은 point cloud를 단순히 이용하여 3D geometry에 대한 다른 input 표현에 초점을 맞춘다.(Raw한 point cloud를 입력으로 취함.)<br><br>
Point cloud는 단순히 점들의 집합이므로 순서에 대해 invariant하며(Permutation invariance), 이것은 Net computation에서 대칭화를 필요로 한다.<br>
또한, rigid motion에도 invariant 해야 한다.(점들을 회전시켜도 분포가 바뀌는건 아니기 때문에)<br><br>

**PointNet**
- Unified Architecture
- 입력 : Raw 3D point cloud data (x;y;z)
- 출력 : class label (classification) or per point segment/part labels

<br>

본 논문의 주요 접근 방식은 다음과 같다.
- use of a single symmetric function, **max pooling**
- network는 point cloud의 흥미롭거나 유용한 점을 선택하고 선택에 대한 이유를 encode하는 일련의 최적화 혹은 기준을 효과적으로 학습한다.
- network의 Fully-connected layer는 학습된 최적 값을 전체 형상에 대한 global descriptor로 모으거나(shape classification), per point label을 예측하는데 사용된다.(shape segmentation)

<br>
Input 형식(3D point cloud)은 각 point가 독립적으로 변환되기에 rigid or affine 변환을 적용하기 쉽다.<br><br>
따라서 PointNet이 데이터를 처리하기 전에 데이터를 정규화(canonicalize)하려고 시도하는 data-dependent spatial transformer network를 추가하여 결과를 개선하였다.<br><br>

(이 다음은 실험, 분석, 평가 방식을 보일 것이고 우수한 이유 설명할 것이고 SOTA 보다 좋은 것을 보일 것이다~~ 라는 introduction)

<br>

**Key contribution**
- Unorderd point sets in 3D를 안정적으로 사용하는 데 적합한 새로운 Deep net architecture를 설계
- 본 network가 3D shape classification, shape part segmentation, scene semantic parsing task들을 수행하도록 학습할 수 있는 방법을 보임
- 안정성, 효율성에 대한 철저한 경험적, 이론적 분석을 제공
- network에서 선택된 neuron에 의해 계산된 3D 특징을 묘사하고, 성능에 대한 직관적인 explanation을 개발

<br>
neural net에서 unordered data를 처리하는 것은 general하고 fundamental한 문제이다.<br>
<br>

# Related Work
**Point Cloud Features**
- point cloud에 대한 대부분의 feature들은 특정 작업을 통해 수작업으로 제작되었다.
- point feature들은 보통 점들의 특정 통계적인 속성을(certain statistical properties) encode하고, 일반적으로 intrinsic 혹은 extrinsic으로 분류되는 특정 변환(certain transformations)에 invariant하도록 설계된다.
- local feature와 global feature들로 분류할 수도 있다.
- 특정 작업에 대해 최적의 feature 조합을 찾는 것은 쉽지 않다.

<br>

**Deep Learning on 3D Data**
- 3D data는 여러 유명한 표현법을 가지고 있기에 학습을 위한 다양한 접근 방식이 존재.
- `Volumetric CNNs` : voxelized shape에  3D convolutional neural networks을 적용한 최초의 접근법.<br>
(그러나 volumetric representation은 data sparsity와 3D 합성곱의 계산 비용으로 인해 해상도에 제약이 존재)<br>(sparsity problem : 실제로 채워진 데이터 포인트보다 비어 있는(0으로 표시되는) 공간이 더 많은 상황을 의미)
- `FPNN`과 `Vote3D`는 희소성 문제(sparsity problem)를 다루기 위한 특별한 방법을 제안했지만 연산이 아직 sparse한 볼륨에서 이루어지므로 매우 큰 point cloud를 처리하는 것은 어렵다.
- `Multiview CNNs` : 3D 포인트 클라우드나 형태를 2D 이미지로 렌더링한 후 2D 컨벌루션 신경망을 적용하여 분류하는 방식을 시도. 형태 분류 및 검색 작업에서 우세한 성능을 달성.
<br>
하지만 이를 scene understanding 혹은 point classification 및 shape completion과 같은 다른 3D작업으로 확장하는 것은 쉽지 않다.

- `Spectral CNNs` : 최근 몇 가지 연구 [4, 16]에서 메쉬(mesh)에 Spectral CNN을 사용.<br>
그러나 이러한 방법은 organic 개체와 같은 manifold 메쉬에 제약 존재. 가구와 같은 non-isometric으로 확장하는 방법은 명확하지 않다.
- `Feature-based DNNs` :  먼저 전통적인 형태 특징을 추출하여 3D 데이터를 벡터로 변환한 다음, Fully-Connected net을 사용하여 형태를 분류. 그러나 추출된 특징의 표현 능력에 제약을 받을 수 있음.

<br>

**Deep Learning on Unordered Sets**
- 데이터 구조적 관점에서 point cloud는 순서가 없는 벡터들의 집합이다.
- 딥러닝에서 대부분의 연구는 음성 및 언어 처리에서의 시퀀스(sequences), 이미지 및 볼륨(비디오 또는 3D 데이터)와 같은 정규화된 입력 표현에 초점을 맞추고 있다.
- 그에 반해 포인트 집합에 대한 딥러닝 연구는 그리 많이 이루어지지 않음.
- Oriol Vinyals et al의 최근 연구 : Attention mechanism을 사용하여 읽기-처리-쓰기 네트워크(read-process-write network)를 사용하여 순서가 없는 입력 집합을 처리.<br>
네트워크가 숫자를 정렬하는 능력을 보여줌.<br>
하지만 일반적인 집합과 자연어 처리(NLP) 응용에 초점을 맞추었기 때문에, 집합 내의 기하학적인 역할에 대한 고려가 부족하다.
<br>
(O. Vinyals, S. Bengio, and M. Kudlur. Order matters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015. 2, 4, 7)

<br>

# Problem statement
위에서 언급했듯이 unordered point 집합을 input로 직접적으로 사용하는 deep learning framework를 디자인한다.<br><br>
- Input : Point cloud<br>
$\{P_i \ \ | \ \ i = 1,...,n\}$<br>
each point $P_i$ is a vector of its $(x,y,z)$
<br><br>

Object classification 분류 작업에서는 input point cloud는 shpae로부터 직접 샘플림되거나 scene point cloud에서 미리 pre-segmented된다.

- Output : object classification<br>
모든 k class 후보에 대한 k score

Semantic segmentation은 입력은 part region segmentation을 위한 single object이거나 object region segmentation을 위한 3D 장면의 sub-volume 일 수 있다.

- Output : sementic classification<br>
모든 n point와 sememtic sub-categories m의 곱<br>
$n * m \ \ score$

<br>

# Deep Learning on Point Sets
## Properties of Point Sets in $\mathbb{R}^n$ 
Our input is a subset of points from an Euclidean space.
<br><br>
세 가지 주요 특성을 가지고 있다.
<br><br>

- **Unordered**
Point cloud는 특정 순서가 없는 점의 집합이다.<br>
즉, N개의 3D Point set을 사용하는 network는 $N!$개의 입력 조합에 대해 invariant해야함.

- **Interaction among points**
점들은 독립적이지 않으며, neighboring points가 meaningful subset을 형성한다.<br>
따라서 모델은 근처의 점들로부터 local structure를 포착할 수 있어야하며, local structure간의 조합적 상호 작용(combinatorial interactions)을 포착할 수 있어야한다.

- **Invariance under transformation**
점들이 모두 회전하거나 이동하여도 point set의 특징이 변화하면 안됨.

## PointNet Architecture
<p align="center"><img src="/MyPDF/PN(2).png" width = "700" ></p>
분류 네트워크는 n개의 점을 입력으로 받아 입력 및 특징 변환을 적용하고, 그 다음 최대 풀링을 통해 점의 특징을 집계.<br>
출력은 k개의 클래스에 대한 분류 점수입니다. 세그멘테이션 네트워크는 분류 네트워크의 확장입니다. 이는 전역 및 지역 특징을 연결하고 점별 점수를 출력합니다.<br>"mlp"는 다중 레이어 퍼셉트론을 나타내며, 괄호 안의 숫자는 각 레이어의 크기입니다. <br>모든 레이어에 ReLU를 사용하여 배치 정규화를 적용합니다. 분류 네트워크의 마지막 mlp에는 드롭아웃 레이어가 사용됩니다.
<br><br>

Classification 네트워크와 segmentation 네트워크는 구조의 상당 부분을 공유한다.<br><br>

**Three key point of network**

- **Symmetric layer**<br>
Input permutation에 대해 모델을 invariant하게 만들기 위한 세 가지 전략이 존재<br><br>1. Input을 canonial하게 정렬 -> 간단해보일 수 있지만 정렬되지 않은 것보다는 나은 성능을 보인다.<br><br>2. RNN 사용 -> RNN을 무작위 순열 시퀀스를 학습시키며 RNN이 입력 순서에 대해 불변해지기를 바라는 것이 주요 아이디어. 하지만  "OrderMatters"에서 저자들은 순서가 중요하며 완전히 무시될 수 없다는 것을 보여줌.<br>일반적인 점 집합의 크기인 수천 개의 입력 요소로 확장하는 것은 어렵다. 성능 또한 bad<br><br>(**2. RNN** : O. Vinyals, S. Bengio, and M. Kudlur. **Order matters**: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015. 2, 4, 7)<br><br>3. simple symmetric 함수를 사용하여 각 점의 정보를 aggregate -> max pooling 사용<br><br>
$f(\{ x_1, ..., x_n \}) \approx g(h(x_1),...,h(x_n))$<br><br>
h는 MLP, g는 max pooling, h의 모음을 통해 집합의 다른 속성을 포착하기 위해 여러 개의 f를 학습할 수 있다.<br><br>

- **Local and Global Information Aggregation**<br>
Symmetric layer 섹션에서 $[f_1,...,f_k]$ 라는 출력 벡터를 형성하며, 이는 입력 집합의 전역적인 특징이다.
<br><br>
점의 segmentation은 local and global knowledge의 조합을 필요로 한다.<br><br>
위의 Figure2.를 통해 확인할 수 있듯이, global point cloud feature vector를  symmetric maxpooling layer로 부터 계산한다.<br><br>
Max pooling 이전 단계에서 구해진 point feature를 global feature와 concatenate(결합)한다.<br><br>
이를 기반으로 새로운 per point feature를 추출한다. 이것은 local과 global information을 동시에 고려한다.<br><br>

- **Joint Alignment Network**<br>
Point cloud가 rigid transformation같은 geometric transformation을 겪어도 point cloud의 semantic labeling은 불변해야한다.<br><br>
다른 방식들보다 훨씬 간단한 방식을 수행.<br>
본 논문에서는 T-net이라는 소규모 network를 통해 Affine transformation matrix를 예측하며, 이 변환을 직접 입력 점으로 적용한다.<br><br>
이 아이디어는 특징 공간의 정렬에 대해서도 더 확장될 수 있다.<br>
Point feature에 또 다른 정렬 네트워크를 삽입하고, 서로 다른 input point cloud에서 나온 특징들을 정렬하기 위해 특징 변환 행렬(feature transformation matrix)을 예측할 수 있다.<br><br>
하지만, feature space에서의 transformation matrix는 spatial transform matrix보다 훨씬 더 높은 차원을 가지기 때문에 최적화의 어려움이 크게 증가한다.<br><br>
그래서 본 눈문에서는 softmax train loss에 정규화 항을 추가하였다.<br><br>
feature transformation matrix를 직교 행렬에 가깝게 제한하였다.<br><br>
$L_{reg}=\left\| I-AA^T \right\|^2_F$<br><br>
A는 소규모 네트워크에 의해 예측된 feature transformation matrix.<br>
정규화 항을 추가함으로써 최적화가 더 안정적이 되고 모델이 더 좋은 성능을 달성.(transformation이 orthogonal 해지면, input에 대한 정보를 잃지 않기 때문)<br>
~~(++ 직교 변환 -> 회전(Rotation), 반사(Reflection), 스케일 변환(Scale) | 직교 행렬이라면, 입력 특징 벡터에 이 변환을 적용하더라도 입력에 대한 정보가 손실되지 않습니다. 직교 변환은 스케일 변환, 회전, 반사 등을 포함할 수 있지만, 이러한 변환은 입력의 구조나 패턴을 유지합니다. 따라서, 직교 변환을 통해 특징을 정렬하면 입력 데이터의 중요한 특징을 보존하면서 정렬된 특징을 얻을 수 있습니다.)~~
<br><br>

# Experiment
<p align="center"><img src="/MyPDF/PN(3).png" width = "500" ></p>
<p align="center"><img src="/MyPDF/PN(4).png" width = "500" ></p>
<p align="center"><img src="/MyPDF/PN(5).png" width = "500" ></p>