---
title : "Lec 10-3: Visdom"
category :
    - Deep_Learning_Study
tag :
    - Deep_Learning
    - Boost Course
toc : true
toc_sticky: true
comments: true
---

Deep_Learning study Lec10-3

## Boostcourseì˜ 'íŒŒì´í† ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹ ê¸°ì´ˆ'ë¥¼ í†µí•œ ê³µë¶€ì™€ ì •ë¦¬ Post    

## Goal of Study  
> - Visdom ì‚¬ìš© ë°©ë²•ì„ ì•Œì•„ë³¸ë‹¤. 

### Keyword
> - Visdom  
> - CNN  
    
## 1. ê°•ì˜ ìš”ì•½  
### Install Visdom
Visdomì„ ì„¤ì¹˜í•´ë³´ì

í•„ìì˜ ê²½ìš° Cë“œë¼ì´ë¸Œê°€ ì•„ë‹Œ Eë“œë¼ì´ë¸Œì˜ ì›í•˜ëŠ” í´ë”ì—ì„œ ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì—

ë‹¤ìŒê³¼ ê°™ì€ ì„ ìˆ˜ ê³¼ì •ì„ ê±°ì¹œë‹¤.

ë¨¼ì € `Activate ìì‹ ì˜ Root`ë¡œ ì„¤ì •í•´ì¤€í›„,

```
E:
```
Eë“œë¼ì´ë¸Œì˜

```
cd DeepLearningStudy
```
ì›í•˜ëŠ” í´ë” í˜¹ì€ ê·¸ëƒ¥ Eë“œë¼ì´ë¸Œì—ë‹¤ í•´ë„ ìƒê´€ì—†ë‹¤.  
ê·¸ëƒ¥ ê´€ë ¨ëœ ëª¨ë“  ê²ƒì„ í•œ ê³³ì—ì„œ ì§„í–‰í•˜ê³  ì‹¶ì–´ ë‹¤ìŒê³¼ ê°™ì´ í•œ ê²ƒ ë¿ì´ë‹¤.

```
pip install visdom
```
ê·¸ í›„ visdom ì„¤ì¹˜ë¥¼ ì§„í–‰í•´ì¤€ë‹¤.

ë‹¤ìŒê³¼ ê°™ë‹¤.
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127967488-028a7eaf-ef98-4bca-9d71-a03b562de975.png" width = "700" ></p>

### Visdom ì„œë²„ ì¼œê¸°
visdom ì„œë²„ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì¼ ë‹¤.

```
python -m visdom.server
```
ê·¸ëŸ¬ë©´ `You can navigate to http://localhost:8097` ë¼ëŠ” ì•ˆë‚´ë¬¸ì´ ëœ¨ê³ , ì € ì£¼ì†Œë¡œ ì„œë²„ê°€ ì‘ë™ì¤‘ì„ì„ ë“¤ì–´ê°€ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

jekyll serverë¥¼ ì¼œëŠ” ê²ƒê³¼ ë¹„ìŠ·í•œê²ƒ ê°™ë‹¤.

### Visdom ì‚¬ìš©ë²•
Visdomì˜ ê°„ë‹¨í•œ ì‚¬ìš©ë²•ì— ëŒ€í•´ ë‹¤ë¤„ë³´ê² ë‹¤.

ì „ì²´ ì½”ë“œ(Jupyter Notebook)ì€ [Github_visdom example]()ì— ì˜¬ë ¤ë†“ì•˜ë‹¤.

```python
import torch
import torch.nn as nn

import torchvision
import torchvision.datasets as dsets
```
```python
import visdom
vis = visdom.Visdom()
```
> Setting up a new session...

visdomì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ `import visdom`ì„ í•´ì£¼ê³   
ì´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ìœ„ì²˜ëŸ¼ ì„ ì–¸í•œë‹¤.

ì´ ê³¼ì •ì—ì„œ ê°€ëŠ¥í•˜ë©´ visdom ì„œë²„ë¥¼ ì¼œë†“ê³  ì§„í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.

#### Text, env
```python
vis.text("Hello, world!",env="main")
```
> 'window_39d6549c2952a8'

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127970413-3b4c4a59-5e12-4c3c-92b3-28b372afc1f9.png" width = "200" ></p>

`.text `ë¥¼ í†µí•´ ë¬¸ìë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤.  
`env = "main"`ì„ í†µí•´ ì–´ë–¤ Environmentì— ì´ë¥¼ ë„ìš¸ ê²ƒì¸ì§€ ì„¤ì •í•œë‹¤. í•œ ë²ˆì— ë„ê±°ë‚˜ ê°™ì€ í™˜ê²½ì—ì„œ ì´ë¥¼ ë‹¤ë£° ë•Œ ì‚¬ìš©í•œë‹¤.



#### image
```python
a=torch.randn(3,200,200)
vis.image(a)
```
ë‹¤ìŒê³¼ ê°™ì´ RGB(3)ì¸ 200 by 200ì˜ ëœë¤ ì´ë¯¸ì§€ë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤.

`.image(param)`ì„ í†µí•´ ì¶œë ¥í•œë‹¤.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127972714-99282d96-4b02-4fea-886f-90df6ac738ab.jpg" width = "200" ></p>

#### Example (using MNIST and CIFAR10)
```python
MNIST = dsets.MNIST(root="./MNIST_data",train = True,transform=torchvision.transforms.ToTensor(), download=True)
cifar10 = dsets.CIFAR10(root="./cifar10",train = True, transform=torchvision.transforms.ToTensor(),download=True)
```
ìœ„ì™€ ê°™ì€ ê³¼ì •ì„ í†µí•´ CIFAR10 MNISTë¥¼ Downloadí•´ì¤€ë‹¤.(ì´ë¯¸ ìˆë‹¤ë©´ ìƒê´€x)
```python
data = cifar10.__getitem__(0)
print(data[0].shape)
vis.images(data[0],env="main")
```
>torch.Size([3, 32, 32])  
'window_39d6593f1e924e'

ê·¸ë¦¬ê³  `__getitem__(0)`ë¥¼ í†µí•´ CIFAR10ì˜ 0ë²ˆì§¸ ì•„ì´í…œì„ ë„ìš¸ ìˆ˜ ìˆë‹¤.

32 by 32 ì˜ ê°œêµ¬ë¦¬(?) ì‚¬ì§„ì´ ë‚˜ì˜¨ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆê³ , (1)ë¡œ ì„¤ì •í•´ë³´ë‹ˆ íŠ¸ëŸ­ì´ ë‚˜ì™”ë‹¤.  
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127975132-33d97175-9905-477d-85f4-5f68b2af9b45.jpg" width = "200" ></p>

MNISTë„ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤.  
```python
data = MNIST.__getitem__(0)
print(data[0].shape)
vis.images(data[0],env="main")
```

#### Check MNIST dataset, .close(env)
```python
data_loader = torch.utils.data.DataLoader(dataset = MNIST,
                                          batch_size = 32,
                                          shuffle = False)
```
ìœ„ì²˜ëŸ¼, batch_sizeë¥¼ 32ë¡œ ì„¤ì •í•´ì£¼ê³ 
```python
for num, value in enumerate(data_loader):
    value = value[0]
    print(value.shape)
    vis.images(value)
    break
```
ì´ë¥¼ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë„ìš°ë©´ 32ê°œì˜ MNIST ë°ì´í„°ê°€ ë‚˜ì˜¨ë‹¤.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127975587-7c87b699-14f8-44fc-a8f5-37c9776f430f.jpg" width = "300" ></p>

```python
vis.close(env="main")
```
ë§ˆì§€ë§‰ìœ¼ë¡œ `vis.close`ë¥¼ ì´ìš©í•´ main envì— ë„ì›Œì ¸ìˆëŠ” í•­ëª©ë“¤ì„ ëª¨ë‘ ë‹«ì„ ìˆ˜ ìˆë‹¤.

#### Line Plot
```python
Y_data = torch.randn(5)
plt = vis.line (Y=Y_data)
```
ë¨¼ì € xì¶•ì˜ ê°’ì„ ë„£ì§€ ì•Šì•˜ì„ ë•Œ 0ê³¼ 1ë²”ìœ„(default)ì—ì„œ nê°œì˜ ì ì„ ëœë¤ìœ¼ë¡œ ì°ëŠ” ì½”ë“œì´ë‹¤.  
ìœ„ì—ì„œ nì€ 5ì´ë‹¤.

`.line`ì„ í†µí•´ ë„ìš´ë‹¤.

```python
X_data = torch.Tensor([1,2,3,4,5])
plt = vis.line(Y=Y_data, X=X_data)
```
xì¶•ì„ ë‹¤ìŒê³¼ ê°™ì´ ì§€ì •í•˜ë©´ ì´ ë²”ìœ„ë‚´ì—ì„œ ì ì„ ì°ì€ ê·¸ë˜í”„ê°€ ë„ì›Œì§„ë‹¤.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127976850-2340ed9c-b941-4cb8-95cc-f54f7a3ea058.png" width = "500" ></p>

##### Line Update
ìš°ë¦¬ê°€ loss functionì„ ì—…ë°ì´íŠ¸í•  ë•Œë¥¼ ìƒê°í•˜ë©´, ì—…ë°ì´íŠ¸ì‹œ ë§ˆë‹¤ plotì„ ì—…ë°ì´íŠ¸ í•´ì¤˜ì•¼í•œë‹¤.
```python
Y_append = torch.randn(1)
X_append = torch.Tensor([6])

vis.line(Y=Y_append, X=X_append, win=plt, update='append')
```
ë°©ë²•ì€, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ Plotì„ ì—…ë°ì´íŠ¸í•´ì¤€ë‹¤.

X, Yì— ë°ì´í„°ë¥¼ ë„£ì–´ì£¼ê³ , ì—…ë°ì´íŠ¸ í•  windowëŠ” `plt`ì´ê³ , updateëŠ” `append`, í™•ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•œë‹¤.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127978052-3d5c847d-5a4f-4efa-aed1-e8189dd7ddea.png" width = "300" ></p>

##### multiple Line on single windows
```python
num = torch.Tensor(list(range(0,10)))
print(num.shape)
num = num.view(-1,1)
print(num.shape)
num = torch.cat((num,num),dim=1)
print(num.shape)

plt = vis.line(Y=torch.randn(10,2), X = num)
```
ì´ì œ ë‘ ê°œì˜ ë¼ì¸ì„ ê·¸ë¦¬ëŠ” ë°©ë²•ì´ë‹¤.

numì„ ì €ë ‡ê²Œ í•´ì£¼ëŠ” ê³¼ì •ì€, indexë¥¼ Yê°’ê³¼ ë§ì¶°ì£¼ê¸° ìœ„í•´ì„œì´ë‹¤.  
(ì¦‰ Yì™€ shapeì„ ë§ì¶”ê¸° ìœ„í•¨)

>
torch.Size([10])  
torch.Size([10, 1])  
torch.Size([10, 2])  

`.view()`ì˜ ì˜ë¯¸ëŠ” -1ì€ ì²«ë²ˆì§¸ ì°¨ì›ì€ ì‚¬ìš©ìê°€ ì˜ ëª¨ë¥´ê² ìœ¼ë‹ˆ íŒŒì´í† ì¹˜ì— ë§¡ê¸°ê² ë‹¤ëŠ” ì˜ë¯¸ì´ê³ , 1ì€ ë‘ë²ˆì§¸ ì°¨ì›ì˜ ê¸¸ì´ëŠ” 1ì„ ê°€ì§€ë„ë¡ í•˜ë¼ëŠ” ì˜ë¯¸ì´ë‹¤.

`torch.cat`ì€ (num, num)ì— ëŒ€í•´ ë”í•˜ê³ ì í•˜ëŠ” ì°¨ì›(dim = 1)ì—ì„œ ë‘ Tensorë¥¼ ë”í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.  
ex)
```python
x = torch.rand(batch_size, N, K) # [M, N, K]
y = torch.rand(batch_size, N, K) # [M, N, K]

output1 = torch.cat([x,y], dim=1) #[M, N+N, K]
output2 = torch.cat([x,y], dim=2) #[M, N, K+K]
```
ê·¸ë˜ì„œ [10, 1]ê³¼ [10, 1], ì¦‰ ê°™ì€ í…ì„œì¸ numì—ì„œ 1ì°¨ì›ì—ì„œ ë‘˜ì„ ë”í•´ì£¼ë©´  
[10, 2]ê°€ ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

##### Line info
```python
plt = vis.line(Y=Y_data, X=X_data, opts = dict(title='Test', showlegend=True))
```
```python
plt = vis.line(Y=Y_data, X=X_data, opts = dict(title='Test', legend = ['1ë²ˆ'],showlegend=True))
```
```python
plt = vis.line(Y=torch.randn(10,2), X = num, opts=dict(title='Test', legend=['1ë²ˆ','2ë²ˆ'],showlegend=True))
```
Plotì˜ infoë¥¼ ì„¤ì •í•´ì£¼ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

`opts`ì—ì„œ `title`ì„ ì„¤ì •í•˜ê±°ë‚˜ Lineì˜ infoë¥¼ ì„¤ì •í•  ë•Œ, `legend`ë¥¼ ëª…ì‹œí•´ì£¼ë©´ plotì— infoë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127982191-3e5a1f3f-4975-4ef8-9bc3-fd2942eb5cc0.png" width = "700" ></p>

### MNIST_Visdom
ì´ì „ì— ë‹¤ë¤„ë³¸ [MNIST_CNN](https://lee-jaewon.github.io/deep_learning_study/Lec10-2/#mnist-cnn)ì—ì„œ layerë‚˜ ë‹¤ë¥¸ ì‚¬í•­ì€ ê°™ê³ ,  
ì´ë¥¼ visdomì— lossë¥¼ trackingí•˜ëŠ” Plotì„ ì–´ë–»ê²Œ ë„ìš°ëŠ”ì§€ ë³´ì.

ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì‚´í´ë³´ë©´,
```python
def loss_tracker(loss_plot, loss_value, num):
    '''num, loss_value, are Tensor'''
    vis.line(X=num,
             Y=loss_value,
             win = loss_plot,
             update='append'
             )
```
ë¨¼ì € ë‹¤ìŒê³¼ ê°™ì´ `loss_tracker`ë¼ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤.

`loss_value`ì—ëŠ” Costì¸ Avg_costë¥¼ ë„£ì–´ì¤„ê²ƒì´ê³ , ì´ëŠ” Yê°’ì¼ ê²ƒì´ë‹¤.

ê·¸ë¦¬ê³  indexë¡œëŠ” epochë¥¼ ë„£ì–´ì¤Œìœ¼ë¡œì¨, epochë§ˆë‹¤ lossê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ update(append)í•´ì¤„ ê²ƒì´ë‹¤.

```python
#Make Plot
loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))
```
ê·¸ë˜í”„ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ì¤€ë‹¤. Yê°’ìœ¼ë¡œëŠ” ì´ˆê¸°í™”ì˜ ì˜ë¯¸(?), ë§¤ê°œë³€ìˆ˜ë¥¼ ì±„ìš°ê¸° ìœ„í•´ 0ì„ ë„£ì—ˆë‹¤.

ê·¸ë¦¬ê³  ì´ë¥¼ í•™ìŠµì„ í•˜ëŠ” ë°˜ë³µë¬¸ì— loss_trackerì˜ `loss_plot' ë¶€ë¶„ì— ë„£ì–´ì¤„ ê²ƒì´ë‹¤.

```python
#training
total_batch = len(data_loader)

for epoch in range(training_epochs):
    avg_cost = 0
    
    for X, Y in data_loader:
        X = X.to(device)
        Y = Y.to(device)
        
        optimizer.zero_grad()
        hypothesis = model(X)
        
        cost = criterion(hypothesis, Y)
        cost.backward()
        optimizer.step()
        
        avg_cost += cost / total_batch
    
    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))
    loss_tracker(loss_plt, torch.Tensor([avg_cost]), torch.Tensor([epoch]))
print('Learning Finished!')
```
ë‹¤ìŒê³¼ ê°™ì´ ë§¤ê°œë³€ìˆ˜ë¥¼ ë„£ì–´ì¤Œìœ¼ë¡œì¨, epochì´ ì§„í–‰í•  ë•Œë§ˆë‹¤, lossê°’ì´ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ì— ëŒ€í•œ ê·¸ë˜í”„ë¥¼ visdomì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127985830-13006e78-18dc-455c-8609-82a045807eaa.png" width = "400" ></p>

ğŸ“£<br>
ë³¸ í¬ìŠ¤íŒ…ì˜ í•™ìŠµ í™˜ê²½ : `Anaconda`, `CPU`, `Pytorch`, `Jupyter Notebook`  
í¬ìŠ¤íŒ…ì—ì„œ ì˜¤ë¥˜ë‚˜ ê¶ê¸ˆí•œ ì ì€ Commentsë¥¼ ì‘ì„±í•´ì£¼ì‹œë©´, ë§ì€ ë„ì›€ì´ ë©ë‹ˆë‹¤.ğŸ’¡  
{: .notice--info}