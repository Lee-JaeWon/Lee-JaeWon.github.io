---
title : "Lec 10-3: Visdom"
category :
    - Deep_Learning_Study
tag :
    - Deep_Learning
    - Boost Course
toc : true
toc_sticky: true
comments: true
---

Deep_Learning study Lec10-3

## Boostcourse의 '파이토치로 시작하는 딥러닝 기초'를 통한 공부와 정리 Post    

## Goal of Study  
> - Visdom 사용 방법을 알아본다. 

### Keyword
> - Visdom  
> - CNN  
    
## 1. 강의 요약  
### Install Visdom
Visdom을 설치해보자

필자의 경우 C드라이브가 아닌 E드라이브의 원하는 폴더에서 설치를 진행하기 때문에

다음과 같은 선수 과정을 거친다.

먼저 `Activate 자신의 Root`로 설정해준후,

```
E:
```
E드라이브의

```
cd DeepLearningStudy
```
원하는 폴더 혹은 그냥 E드라이브에다 해도 상관없다.  
그냥 관련된 모든 것을 한 곳에서 진행하고 싶어 다음과 같이 한 것 뿐이다.

```
pip install visdom
```
그 후 visdom 설치를 진행해준다.

다음과 같다.
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127967488-028a7eaf-ef98-4bca-9d71-a03b562de975.png" width = "700" ></p>

### Visdom 서버 켜기
visdom 서버는 다음과 같이 켠다.

```
python -m visdom.server
```
그러면 `You can navigate to http://localhost:8097` 라는 안내문이 뜨고, 저 주소로 서버가 작동중임을 들어가서 확인할 수 있다.

jekyll server를 켜는 것과 비슷한것 같다.

### Visdom 사용법
Visdom의 간단한 사용법에 대해 다뤄보겠다.

전체 코드(Jupyter Notebook)은 [Github_visdom example]()에 올려놓았다.

```python
import torch
import torch.nn as nn

import torchvision
import torchvision.datasets as dsets
```
```python
import visdom
vis = visdom.Visdom()
```
> Setting up a new session...

visdom을 사용하기 위해 `import visdom`을 해주고  
이를 사용하기 위해 위처럼 선언한다.

이 과정에서 가능하면 visdom 서버를 켜놓고 진행하는 것이 좋다.

#### Text, env
```python
vis.text("Hello, world!",env="main")
```
> 'window_39d6549c2952a8'

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127970413-3b4c4a59-5e12-4c3c-92b3-28b372afc1f9.png" width = "200" ></p>

`.text `를 통해 문자를 띄울 수 있다.  
`env = "main"`을 통해 어떤 Environment에 이를 띄울 것인지 설정한다. 한 번에 끄거나 같은 환경에서 이를 다룰 때 사용한다.



#### image
```python
a=torch.randn(3,200,200)
vis.image(a)
```
다음과 같이 RGB(3)인 200 by 200의 랜덤 이미지를 띄울 수 있다.

`.image(param)`을 통해 출력한다.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127972714-99282d96-4b02-4fea-886f-90df6ac738ab.jpg" width = "200" ></p>

#### Example (using MNIST and CIFAR10)
```python
MNIST = dsets.MNIST(root="./MNIST_data",train = True,transform=torchvision.transforms.ToTensor(), download=True)
cifar10 = dsets.CIFAR10(root="./cifar10",train = True, transform=torchvision.transforms.ToTensor(),download=True)
```
위와 같은 과정을 통해 CIFAR10 MNIST를 Download해준다.(이미 있다면 상관x)
```python
data = cifar10.__getitem__(0)
print(data[0].shape)
vis.images(data[0],env="main")
```
>torch.Size([3, 32, 32])  
'window_39d6593f1e924e'

그리고 `__getitem__(0)`를 통해 CIFAR10의 0번째 아이템을 띄울 수 있다.

32 by 32 의 개구리(?) 사진이 나온것을 확인할 수 있었고, (1)로 설정해보니 트럭이 나왔다.  
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127975132-33d97175-9905-477d-85f4-5f68b2af9b45.jpg" width = "200" ></p>

MNIST도 같은 과정으로 데이터를 띄울 수 있다.  
```python
data = MNIST.__getitem__(0)
print(data[0].shape)
vis.images(data[0],env="main")
```

#### Check MNIST dataset, .close(env)
```python
data_loader = torch.utils.data.DataLoader(dataset = MNIST,
                                          batch_size = 32,
                                          shuffle = False)
```
위처럼, batch_size를 32로 설정해주고
```python
for num, value in enumerate(data_loader):
    value = value[0]
    print(value.shape)
    vis.images(value)
    break
```
이를 다음과 같은 방법으로 띄우면 32개의 MNIST 데이터가 나온다.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127975587-7c87b699-14f8-44fc-a8f5-37c9776f430f.jpg" width = "300" ></p>

```python
vis.close(env="main")
```
마지막으로 `vis.close`를 이용해 main env에 띄워져있는 항목들을 모두 닫을 수 있다.

#### Line Plot
```python
Y_data = torch.randn(5)
plt = vis.line (Y=Y_data)
```
먼저 x축의 값을 넣지 않았을 때 0과 1범위(default)에서 n개의 점을 랜덤으로 찍는 코드이다.  
위에서 n은 5이다.

`.line`을 통해 띄운다.

```python
X_data = torch.Tensor([1,2,3,4,5])
plt = vis.line(Y=Y_data, X=X_data)
```
x축을 다음과 같이 지정하면 이 범위내에서 점을 찍은 그래프가 띄워진다.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127976850-2340ed9c-b941-4cb8-95cc-f54f7a3ea058.png" width = "500" ></p>

##### Line Update
우리가 loss function을 업데이트할 때를 생각하면, 업데이트시 마다 plot을 업데이트 해줘야한다.
```python
Y_append = torch.randn(1)
X_append = torch.Tensor([6])

vis.line(Y=Y_append, X=X_append, win=plt, update='append')
```
방법은, 다음과 같은 방법으로 Plot을 업데이트해준다.

X, Y에 데이터를 넣어주고, 업데이트 할 window는 `plt`이고, update는 `append`, 확장하는 방식으로 진행한다.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127978052-3d5c847d-5a4f-4efa-aed1-e8189dd7ddea.png" width = "300" ></p>

##### multiple Line on single windows
```python
num = torch.Tensor(list(range(0,10)))
print(num.shape)
num = num.view(-1,1)
print(num.shape)
num = torch.cat((num,num),dim=1)
print(num.shape)

plt = vis.line(Y=torch.randn(10,2), X = num)
```
이제 두 개의 라인을 그리는 방법이다.

num을 저렇게 해주는 과정은, index를 Y값과 맞춰주기 위해서이다.  
(즉 Y와 shape을 맞추기 위함)

>
torch.Size([10])  
torch.Size([10, 1])  
torch.Size([10, 2])  

`.view()`의 의미는 -1은 첫번째 차원은 사용자가 잘 모르겠으니 파이토치에 맡기겠다는 의미이고, 1은 두번째 차원의 길이는 1을 가지도록 하라는 의미이다.

`torch.cat`은 (num, num)에 대해 더하고자 하는 차원(dim = 1)에서 두 Tensor를 더하는 함수이다.  
ex)
```python
x = torch.rand(batch_size, N, K) # [M, N, K]
y = torch.rand(batch_size, N, K) # [M, N, K]

output1 = torch.cat([x,y], dim=1) #[M, N+N, K]
output2 = torch.cat([x,y], dim=2) #[M, N, K+K]
```
그래서 [10, 1]과 [10, 1], 즉 같은 텐서인 num에서 1차원에서 둘을 더해주면  
[10, 2]가 됨을 확인할 수 있다.

##### Line info
```python
plt = vis.line(Y=Y_data, X=X_data, opts = dict(title='Test', showlegend=True))
```
```python
plt = vis.line(Y=Y_data, X=X_data, opts = dict(title='Test', legend = ['1번'],showlegend=True))
```
```python
plt = vis.line(Y=torch.randn(10,2), X = num, opts=dict(title='Test', legend=['1번','2번'],showlegend=True))
```
Plot의 info를 설정해주는 방법은 다음과 같다.

`opts`에서 `title`을 설정하거나 Line의 info를 설정할 때, `legend`를 명시해주면 plot에 info를 설정할 수 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127982191-3e5a1f3f-4975-4ef8-9bc3-fd2942eb5cc0.png" width = "700" ></p>

### MNIST_Visdom
이전에 다뤄본 [MNIST_CNN](https://lee-jaewon.github.io/deep_learning_study/Lec10-2/#mnist-cnn)에서 layer나 다른 사항은 같고,  
이를 visdom에 loss를 tracking하는 Plot을 어떻게 띄우는지 보자.

변경된 부분만 살펴보면,
```python
def loss_tracker(loss_plot, loss_value, num):
    '''num, loss_value, are Tensor'''
    vis.line(X=num,
             Y=loss_value,
             win = loss_plot,
             update='append'
             )
```
먼저 다음과 같이 `loss_tracker`라는 함수를 만들어준다.

`loss_value`에는 Cost인 Avg_cost를 넣어줄것이고, 이는 Y값일 것이다.

그리고 index로는 epoch를 넣어줌으로써, epoch마다 loss가 어떻게 변하는지 update(append)해줄 것이다.

```python
#Make Plot
loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))
```
그래프는 다음과 같이 설정해준다. Y값으로는 초기화의 의미(?), 매개변수를 채우기 위해 0을 넣었다.

그리고 이를 학습을 하는 반복문에 loss_tracker의 `loss_plot' 부분에 넣어줄 것이다.

```python
#training
total_batch = len(data_loader)

for epoch in range(training_epochs):
    avg_cost = 0
    
    for X, Y in data_loader:
        X = X.to(device)
        Y = Y.to(device)
        
        optimizer.zero_grad()
        hypothesis = model(X)
        
        cost = criterion(hypothesis, Y)
        cost.backward()
        optimizer.step()
        
        avg_cost += cost / total_batch
    
    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))
    loss_tracker(loss_plt, torch.Tensor([avg_cost]), torch.Tensor([epoch]))
print('Learning Finished!')
```
다음과 같이 매개변수를 넣어줌으로써, epoch이 진행할 때마다, loss값이 어떻게 변화하는지에 대한 그래프를 visdom을 통해 확인할 수 있다.

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/127985830-13006e78-18dc-455c-8609-82a045807eaa.png" width = "400" ></p>

📣<br>
본 포스팅의 학습 환경 : `Anaconda`, `CPU`, `Pytorch`, `Jupyter Notebook`  
포스팅에서 오류나 궁금한 점은 Comments를 작성해주시면, 많은 도움이 됩니다.💡  
{: .notice--info}