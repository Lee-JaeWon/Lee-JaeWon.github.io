---
title : "Deep_Learning study Lec05"
category :
    - Deep_Learning_Study
tag :
    - Deep_Learning
    - Boost Course
toc : true
toc_sticky: true
comments: true
---

Lec 05: Logistic Regression/Classification

## Boostcourse의 '파이토치로 시작하는 딥러닝 기초'를 통한 공부와 정리 Post

'파이토치로 시작하는 딥러닝 기초'와 '텐서플로우로 시작하는 딥러닝 기초'를 함께 공부하며 개념적인 부분에서 상호보완하고 있기 때문에 다른 포스트에서 같은 내용을 다루는 부분이 있을 수 있습니다.  

## Goal of Study
> - 로지스틱 회귀/분류(Logistic Regression/Classification)의 개념을 알아본다.  

### Keyword
> - 로지스틱 회귀 / 분류(Logistic Regression / Classification)  
> - 가설(Hypothesis)  
> - 시그모이드 / 로지스틱(Sigmoid / Logistic)   

## 1. 강의 요약  
### Classification(binary)
머신 러닝을 하기 위해서는 binary Classification을 하기 위한 두 가지의 값으로 나뉘어야 한다.  

데이터의 특징을 토대로 케이스를 두 가지로 분류할 수 있으며,  

이를 바탕으로 Logistic Regression Model을 만들게 된다.

### Logistic VS Linear
Logistic Regression을 적용하기 위한 데이터의 경우에는  
구분선으로 케이스를 두 가지로 **구분**해낼 수 있는 데이터이다.

이에 반해, Linear Regression의 경우에는 데이터들이 **연속적**이다.  
이러한 연속적인 경향들의 값을 학습해 새로운 데이터에 대해 예측하는 것이다.  
(ex, Time, Weight, Height)

### Hypothesis Representation
합격과 불합격을 공부 시간에 따라 예측할 때,  

우리가 원하는 것은 Linear한 수치형 데이터가 아닌  
정확히 0과 1로 구분해내는 binary classification에 대한 결괏값에 필요하다.  
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/126043340-71ffbd21-b547-4769-97fe-81fbb8dc3299.png" width = "400" ></p>


그러므로, 새로운 수식이 필요하다.

원하는 Hypothesis를 표현하기 위해서는 다음과 같은 과정이 필요하다.  
(세타는 Weight이다.)
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/126043395-6944c19b-d4f8-46cc-927a-a9b41011b5e3.png" width = "400" ></p>

기존과 같이 X에 Weight를 곱하여 Linear한 값이 나오게 되는데,  

이 값을 Logistic function을 통해서 0과 1의 **구간**으로 표현할 수 있고,  

이를 특정 Decision Boundary를 통해 0과 1을 출력해내는 것이 우리가 원하는 Hypothesis이다.

### Sigmoid (Logistic) function  
Logistic function => g(z) function  
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/126043542-1a980937-ead8-4321-92cf-c25a3c4e7631.png" width = "400" ></p>

지수 함수의 성질에 따라 g(z)함수에서 z가 무한대에 가까워지면 e^(-z)는 0에 가까워지므로,  

g(z)가 1에 점점 수렴하게 된다. 역은 0에 수렴하게 되는 것을 알 수 있다.  

이를 Sigmoid 함수라고 한다.  

### Decision Boundary
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/126043619-54aa78af-4401-43df-9f25-bff4e0766cc3.png" width = "300" ></p>

조금 더 자세히 살펴보면, 우리가 필요로 하는 것은 1과 0일때,  

Sigmoid를 통해서 값이 나온 것을
Decision Boundary인 0.5를 기준으로 나누게 된다.

즉, 구간을 결정하는 것이 Decision Boundary이다.

Linear이든, non-Linear이든 이를 구분하는 경계선(Decision Boundary)을 기준으로 구분해낼 수 있다.