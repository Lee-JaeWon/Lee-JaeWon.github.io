---
title : "Lec 08: Perceptron"
category :
    - Deep_Learning_Study
tag :
    - Deep_Learning
    - Boost Course
toc : true
toc_sticky: true
comments: true
---

Deep_Learning study Lec08 

## Boostcourse의 '파이토치로 시작하는 딥러닝 기초'를 통한 공부와 정리 Post    

## Goal of Study  
> - 퍼셉트론(Perceptron) 에 대해 알아본다. 

### Keyword
> - 퍼셉트론(Perceptron)  
> - 선형분류기(Linear Classifier)  
> - AND, OR, XOR 게이트    

## 1. 강의 요약  
### Neuron
먼저 인공신경망이 무엇인지 알아보자.  

우리가 생명시간에 한번쯤은 배워봤을 내용인 뇌의 뉴런이라는 것의 동작 방식을 본떠 만든 모델이다.  

뉴런의 동작 방식은 단순하다.  
뉴런에 들어온 입력 신호가 threshold를 넘어서면 활성화되어 다음 뉴런으로 전달하는 방식이다.

이를 본따 만든 모델을 **인공 신경망**이라고 한다.

### Perceptron
인공 신경망중 하나인 Perceptron에 대해 알아보자.  

Perceptron은 어떠한 입력 X가 들어왔을 때 이 X들의 Weight,  
즉, 가중치를 곱하고 이에 bias를 더하여 output을 만들게 된다.

이 ouuput은 Activation function이라는 것을 거쳐 최종적인 output이 나오게 되는 것이고,  
우리가 앞서 다루었던 Sigmoid 함수 같은 것이 이에 해당한다.  

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/126859432-d49b0463-38d7-4c89-bde9-9793ea2bebab.png" width = "400" ></p>

초창기의 Perceptron은 Linear classifier를 위한 모델이었다.

실제 개발 당시에, AND와 OR 문제를 해결하기 위해서 만들어졌다.

### AND, OR But XOR?
특별한 것 없이 우리가 아는 AND와 OR Gate이다.

AND와 OR같은 경우는 Linear하게 분류가 가능하다.

하지만, XOR 같은 경우  
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/126860101-2e399f0d-ecd9-4d3c-9f9b-689d990807c9.jpg" width = "300" ></p>

다음과 같은 데이터를 AND, OR과 달리 Linear하게 분류가능한가?

<p align="center"><img src="https://user-images.githubusercontent.com/72693388/126860126-95d2bcb4-7cba-472a-a1c0-a71c07931d71.png" width = "400" ></p>  
선형적인 형태로는 가능하지 않다. 이 때문에 개발당시 인공신경망이 암흑기에 빠졌다고 한다.  
그래서 XOR을 구분할 때, Linear한 Classifier인 Perceptron은 불가능하다.

이를 확인하기 위해 Perceptron 즉, 1개의 layer를 가지는 구조를 통해 코드로 구현하여  
학습시켜보겠다.  

예제 코드)  
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/126860266-c962e34a-efc9-4931-88cd-1653bfc6856d.png" width = "500" ></p>

linear한 layer를 사용하였고, activation function으로는 sigmoid 함수를 사용하였다.  

그리고 bianry classification에 관한 문제이므로 cost function은 Cross entropy를 사용한것을 확인할 수 있다.

optimizer는 이전에도 사용해왔던 일반적인 SGD를 사용하였고, 결과를 확인하면(10000번 학습)  

200번째 step부터는 loss가 줄어들지 않는 것을 확인할 수 있으며(제대로 학습이 되지 않음)

학습이 끝난 후 각 결과를 확인했을때, Perceptron이 0.5만 출력해, 결과와 맞지 않는 것을 확인할 수 있다.  
(실제 답은 0, 1, 1, 0 )  


