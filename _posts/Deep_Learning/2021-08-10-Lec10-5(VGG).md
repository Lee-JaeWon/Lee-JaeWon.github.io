---
title : "Lec 10-5: Advanced CNN - VGG"
category :
    - Deep_Learning_Study
tag :
    - Deep_Learning
    - Boost Course
toc : true
toc_sticky: true
comments: true
---

Deep_Learning study Lec10-5

## Boostcourseì˜ 'íŒŒì´í† ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹ ê¸°ì´ˆ'ë¥¼ í†µí•œ ê³µë¶€ì™€ ì •ë¦¬ Post    

## Goal of Study  
> - ìœ ëª…í•œ CNN ëª¨ë¸ë“¤ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.  

### Keyword
> - VGG    
> - CNN  
    
## 1. ê°•ì˜ ìš”ì•½  
### VGG
[ì´ì „ í¬ìŠ¤íŒ…ì˜ ê°ì¢… Advanced CNN ì†Œê°œ](https://lee-jaewon.github.io/deep_learning_study/Lec10-5/)ì— ì´ì–´ì„œ VGG NetWorkë¥¼ ë§Œë“¤ì–´ë³´ë„ë¡ í•˜ê² ë‹¤.

### VGGnet_layer
ê¸°ë³¸ì ì¸ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
<p align="center"><img src="https://user-images.githubusercontent.com/72693388/128819718-20f05082-37f3-49cf-9507-4273644ee154.png" width = "500" ></p>

ëª¨ë‘ 3x3 Conv, stride = 1, padding = 1ë¡œ ì´ë£¨ì–´ì ¸ ìˆì–´, êµ¬ì¡°ê°€ ì–´ë ¤ìš´ í¸ì€ ì•„ë‹ˆë‹¤.(ìœ„ì˜ ì‚¬ì§„ì€ VGG16)

ê¸°ì´ˆì ìœ¼ë¡œ ë‹¤ë¤„ì•¼í•  ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
> - vgg11 ~ vgg19 ê¹Œì§€ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ ë˜ì–´ìˆìŒ  
> - 3x224x224 ì…ë ¥ì„ ê¸°ì¤€ìœ¼ë¡œ ë§Œë“¤ë„ë¡ ë˜ì–´ ìˆìŒ(RGB)   
> - input sizeê°€ ë‹¤ë¥¸ ê²½ìš° VGGë¥¼ ì ìš©í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œ?  

Layerë¥¼ ë¨¼ì € ë‹¤ë¤„ë³´ì.
```python
import torch.nn as nn
import torch.utils.model_zoo as model_zoo
```
```python
__all__ = [
    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',
    'vgg19_bn', 'vgg19',
]


model_urls = {
    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',
    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',
    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',
    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',
    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',
    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',
    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',
    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',
}
```
ìœ„ì˜ urlë“¤ì€ pytorchì—ì„œ VGGì— ëŒ€í•´ ì´ë¯¸ pre-training ì‹œì¼œë†“ì€ ëª¨ë¸ì´ë‹¤.  

```python
class VGG(nn.Module):
    def __init__(self, features, num_classes=1000, init_weights=True):
        super(VGG, self).__init__()
        
        self.features = features #convolution
        
        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))
        
        self.classifier = nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, num_classes),
        )#FC layer
        
        if init_weights:
            self._initialize_weights()

    def forward(self, x):
        x = self.features(x) #Convolution 
        x = self.avgpool(x) # avgpool
        x = x.view(x.size(0), -1) #
        x = self.classifier(x) #FC layer
        return x

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
```

VGG í´ë˜ìŠ¤ì´ë‹¤.

ë¨¼ì € inputìœ¼ë¡œ ë°›ëŠ”ê°’ì€ 3ê°œì´ë©°, featureì—ì„œ ë°›ì•„ì˜¨ Convolution layerë¥¼ í†µí•´  
`forward`ê³¼ì •ì—ì„œ `self.features`ì— input ê°’ì´ ë“¤ì–´ê°€ì„œ ë‚˜ì˜¤ê²Œ ë˜ê³ ,

[Avg pooling](https://lee-jaewon.github.io/deep_learning_study/Lec10-1/#average-pooling) ì´í›„ì— ì´ë¥¼ í¼ì³ì„œ, classifierì— ë“¤ì–´ê°€ê²Œ ë˜ì–´ìˆë‹¤.

classifierëŠ” ì½”ë“œì—ì„œë„ ë³¼ ìˆ˜ ìˆë“¯ì´, `nn.Sequential`ì„ ì´ìš©í•´ Fully Connected layerë¥¼ êµ¬ì„±í•œ ê²ƒì´ë‹¤.

[ì´ì „ í¬ìŠ¤íŒ…ì˜ VGG Net](https://lee-jaewon.github.io/deep_learning_study/Lec10-5/#vggnet)ì—ì„œ ConvNetì— ëŒ€í•œ Configurationì„ ì˜¬ë ¤ë†“ì•˜ë‹¤.

ì´ë¥¼ ì‚´í´ë³´ë©´, ë§ˆì§€ë§‰ì— Layer í•˜ë‹¨ì— FC Layerê°€ **3ê°œ**ì¸ë°, `nn.Sequential`ì˜ 3ê°œì˜ FC Layerê°€ ì´ê²ƒê³¼ ê°™ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

`nn.Sequential`ì—ì„œ ë§ˆì§€ë§‰ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” classì˜ ê°œìˆ˜(`num_classes`) ë˜í•œ, ë§¤ê°œë³€ìˆ˜ë¡œì¨ ë¹¼ë¨¹ì§€ ë§ê³  ë‹¤ë¤„ì¤˜ì•¼í•œë‹¤. 

---  
Weight Initialization ê³¼ì •ì„ ì‚´í´ë³´ê¸° ìœ„í•´,  
`self.modules`ì— ëŒ€í•´ ë¨¼ì € ì‚´í´ë³´ì.  

"The self.modules() method returns an iterable to the many layers or â€œmodulesâ€ defined in the model class."   
[ì¶œì²˜ : Pytorch discuss](https://discuss.pytorch.org/t/pytorch-self-module/49677)

ì¦‰, `self.modules` ë©”ì†Œë“œëŠ” ëª¨ë¸ í´ë˜ìŠ¤ì— ì •ì˜ëœ ë§ì€ ë ˆì´ì–´ ë˜ëŠ” "ëª¨ë“ˆ"ì— ëŒ€í•´ **ë°˜ë³µ ê°€ëŠ¥í•œ í•­ëª©ì„ ë°˜í™˜**í•œë‹¤ê³  ì„¤ëª…í•˜ê³  ìˆëŠ” ê²ƒê°™ë‹¤.

ì—¬ê¸°ì„œëŠ” `features`ì— ë“¤ì–´ì˜¤ëŠ” Convolution Layerì˜ ê°’ì„ í•˜ë‚˜ì”© ë°›ì•„ì˜¤ë©´ì„œ, mì´ ì–´ë–¤ ê²ƒì¸ì§€ì— ë”°ë¼ Weightë¥¼ ì–´ë–»ê²Œ ì´ˆê¸°í™” ì‹œì¼œì¤„ ê²ƒì¸ì§€ ë‚˜íƒ€ë‚¸ ì½”ë“œì´ë‹¤.

>
mì— Convê°€ ë“¤ì–´ì˜¤ë©´, kalming_normalizationì„ í†µí•´ weightë¥¼ ì´ˆê¸°í™”í•´ì£¼ê³ ,  
biasëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™” í•´ì¤€ë‹¤.
>
mì´ BatchNorm2dì´ë©´, ì´ì— ëŒ€í•´ì„œë„ Normalizeë¥¼ ì¡ì•„ì£¼ê³ (ì „ë¶€ë‹¤ 1),  
biasë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™” í•´ì¤€ë‹¤.
>
Linearì¸ ê²½ìš°ë„ ë§ˆì°¬ê°€ì§€ë¡œ ì§„í–‰ë¨ì„ ì•Œ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

ê·¸ëŸ¼ ì´ì œ, featureë¥¼ ì–´ë–»ê²Œ ë„£ì–´ì¤„ ì§€ë¥¼ ì•„ë˜ `make_layers`ì™€ `cfg`ë¥¼ í†µí•´ ì•Œì•„ë³´ì.
```python
def make_layers(cfg, batch_norm=False):
    layers = [] 
    in_channels = 3
    
    for v in cfg:
        if v == 'M':
            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
        else:
            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
            if batch_norm:
                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]
            else:
                layers += [conv2d, nn.ReLU(inplace=True)]
            in_channels = v
                     
    return nn.Sequential(*layers)
```
```python
cfg = {
    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], #8 + 3 =11 == vgg11
    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], # 10 + 3 = vgg 13
    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], #13 + 3 = vgg 16
    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'], # 16 +3 =vgg 19
    'custom' : [64,64,64,'M',128,128,128,'M',256,256,256,'M']
}
```
`cfg`ëŠ” `make_layers`ì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ë“¤ì–´ê°€ì„œ `nn.Conv2d`ì˜ out_channelì´ ëœë‹¤.

ì¦‰, ì²˜ìŒì˜ input_channel 3ì—ì„œ ìš°ë¦¬ê°€ ë„£ì–´ì¤€ `cfg`ë¥¼ í†µí•´ out_channelì„ ê²°ì •í•´ì£¼ë©°, Layerë¥¼ ìŒ“ì•„ì£¼ëŠ” ê²ƒì´ë‹¤.

ë¦¬ìŠ¤íŠ¸ì˜ `'M'`ì€ Maxpoolingì„ ìˆ˜í–‰í•œë‹¤.

ë°˜í™˜ì€ layerë“¤ì„ `nn.Sequential`ì— ë„£ì–´ì¤€ ê²ƒì„ ë°˜í™˜í•œë‹¤.

VGGì˜ ìˆ«ìëŠ” FC layer 3ê°œë¥¼ ë”í•œ ê°’ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```python
conv = make_layers(cfg['custom'], batch_norm=True)
```
BatchNormì„ ì¶”ê°€í•œ conv í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤

>
Sequential(  
  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (2): ReLU(inplace=True)  
  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (5): ReLU(inplace=True)  
  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (8): ReLU(inplace=True)  
  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  
  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (12): ReLU(inplace=True)  
  (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (15): ReLU(inplace=True)  
  (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (18): ReLU(inplace=True)  
  (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  
  (20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (22): ReLU(inplace=True)  
  (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (25): ReLU(inplace=True)  
  (26): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
  (27): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  
  (28): ReLU(inplace=True)  
  (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  
)
```python
CNN = VGG(make_layers(cfg['custom']), num_classes=10, init_weights=True)
```
```python
CNN
```
> result  
>  
VGG(  
(features): Sequential(  
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
    (1): ReLU(inplace=True)  
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
    (3): ReLU(inplace=True)  
    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
    (5): ReLU(inplace=True)  
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
    (8): ReLU(inplace=True)  
    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
    (10): ReLU(inplace=True)  
    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
    (12): ReLU(inplace=True)  
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)   
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))   
    (15): ReLU(inplace=True)  
    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
    (17): ReLU(inplace=True)  
    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  
    (19): ReLU(inplace=True)  
    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  
)  
(avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  
(classifier): Sequential(  
    (0): Linear(in_features=25088, out_features=4096, bias=True)  
    (1): ReLU(inplace=True)  
    (2): Dropout(p=0.5, inplace=False)  
    (3): Linear(in_features=4096, out_features=4096, bias=True)  
    (4): ReLU(inplace=True)  
    (5): Dropout(p=0.5, inplace=False)  
    (6): Linear(in_features=4096, out_features=10, bias=True)  
    )  
)  

ì™„ì„±ëœ VGG netì˜ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ë©´, ìœ„ì™€ ê°™ë‹¤.

### í•™ìŠµ ì½”ë“œ
ì•„ë˜ì˜ ì½”ë“œëŠ” ë¡œì»¬ì—ì„œ ì§„í–‰í•  ìˆ˜ ìˆëŠ” ì½”ë“œì´ë‹¤.

ë³¸ì¸ì€ ë¡œì»¬ì—ì„œ ì§„í–‰í•˜ë‹¤ í•™ìŠµì‹œê°„ì´ ì˜¤ë˜ê±¸ë ¤ CoLabì—ì„œ ë‹¤ì‹œ ì§„í–‰í–ˆë‹¤.  
Colabì—ì„œë„ ìƒë‹¹íˆ ì˜¤ë˜ê±¸ë¦¬ê³ , Colabì—ì„œëŠ” ë°˜ì‘ì´ ì—†ê±°ë‚˜ ì¼ì •ì‹œê°„ì´ ì§€ë‚˜ë©´ ì¤‘ë‹¨ë˜ëŠ” ê²½ìš°ê°€ ìˆì–´

ê²°ê³¼ëŠ” ì ì‹œ ë¯¸ë¤„ë‘ê³  ì½”ë“œë¥¼ ìš°ì„ ìœ¼ë¡œ ë³´ê² ë‹¤.

#### ê¸°ë³¸ì„¤ì •
```python
import torch
import torch.nn as nn

import torch.optim as optim

import torchvision
import torchvision.transforms as transforms
```
```python
import visdom

vis = visdom.Visdom()
vis.close(env="main")
```
>Setting up a new session...  
''

visdomì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì„¤ì •.
```python
def loss_tracker(loss_plot, loss_value, num):
    '''num, loss_value, are Tensor'''
    vis.line(X=num,
             Y=loss_value,
             win = loss_plot,
             update='append'
             )
```
```python
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)

torch.manual_seed(777)
if device =='cuda':
    torch.cuda.manual_seed_all(777)
```
> cpu

```python
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,
                                          shuffle=True, num_workers=4)

testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,
                                       download=True, transform=transform)

testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=4)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```
>
Files already downloaded and verified  
Files already downloaded and verified

Colabì—ì„œëŠ” `num_workes`ê°€ 2ê°€ ë„˜ìœ¼ë©´ ì•ˆëœë‹¤ê³  ê²½ê³ í•œë‹¤.
```python
import matplotlib.pyplot as plt
import numpy as np
%matplotlib inline
# functions to show an image

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()
vis.images(images/2 + 0.5)

# show images
#imshow(torchvision.utils.make_grid(images))

# print labels
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
```
> truck   car   car   cat
- img show

ìœ„ê¹Œì§€ í•´ì„œ ê¸°ë³¸ì ì¸ ì„¤ì •ë“¤ì„ ì§„í–‰í•´ì¤€ë‹¤.
#### VGG Net
```python
import vgg
#import torchvision.models.vgg as vgg
```
ì£¼ì˜ì ì€ vgg.pyë¥¼ ê°™ì€ rootì— ìƒì„±í•´ë†“ì€ ê²ƒì´ ì•„ë‹ˆë¼ë©´ ì•„ë˜ì¤„ì˜ ì½”ë“œë¥¼ ì‚¬ìš©í•´ì•¼í•œë‹¤.  
[ê°•ì˜ ì°¸ê³ ](https://www.boostcourse.org/ai214/lecture/43769?isDesc=false)
```python
cfg = [32,32,'M', 64,64,128,128,128,'M',256,256,256,512,512,512,'M'] #13 + 3 =vgg16
```
cfgëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

vgg16ì„ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.
```python
class VGG(nn.Module):

    def __init__(self, features, num_classes=1000, init_weights=True):
        super(VGG, self).__init__()
        self.features = features
        #self.avgpool = nn.AdaptiveAvgPool2d((7, 7))
        self.classifier = nn.Sequential(
            nn.Linear(512 * 4 * 4, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, num_classes),
        )
        if init_weights:
            self._initialize_weights()

    def forward(self, x):
        x = self.features(x)
        #x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
```
ë³¸ í¬ìŠ¤íŒ…ìœ„ì—ì„œ Layerë¥¼ ë§Œë“œëŠ” ê²ƒê³¼ ê°™ì€ ê³¼ì •ì´ë‹¤.

512 * 4 * 4 ì¸ ì´ìœ ëŠ” Max Poolingì„ 3ë²ˆ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì— 512ì±„ë„ì˜ 4 by 4ê°€ ìƒì„±ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.  

```python
vgg16= VGG(vgg.make_layers(cfg),10,True).to(device)
```
num_classesëŠ” 10ê°œë¡œ ë°›ëŠ”ë‹¤.

make_layersë„ ìœ„ì—ì„œ ë‹¤ë£¨ì—ˆë‹¤.

```python
a=torch.Tensor(1,3,32,32).to(device)
out = vgg16(a)
print(out)
```
- ê²°ê³¼ í™•ì¸  
>tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],  
    grad_fn=<AddmmBackward>)

```python
criterion = nn.CrossEntropyLoss().to(device)
optimizer = torch.optim.SGD(vgg16.parameters(), lr = 0.005,momentum=0.9)

lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)
```
ì´ë²ˆ ì½”ë“œì—ì„œ ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„ì€ `lr_sche`ì´ë‹¤.

í•™ìŠµ ì¤‘ì— learning rateë¥¼ ê³ ì •ì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹Œ learning rateë¥¼ ê³„ì†í•´ì„œ ìˆ˜ì •í•˜ë©°, ì¡°ê¸ˆ ë” ì •ë°€í•œ í•™ìŠµì„ í•  ìˆ˜ ìˆë„ë¡ í•´ì¤€ë‹¤.

`step_size=5`ëŠ” sche.stepì„ 5ë²ˆì”© í•  ë•Œë§ˆë‹¤ learning rateì— 0.9(`gamma=0.9`)ì”© ê³±í•˜ë¼ë¼ëŠ” ëœ»ì´ë‹¤.

`lr_sche.step()`ì€ ì•„ë˜ í•™ìŠµ ì½”ë“œì— ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```python
loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))
```
```python
print(len(trainloader))
epochs = 50

for epoch in range(epochs):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
    
        #zero the parameter gradients
        optimizer.zero_grad()
    
        #forward + backward + optimize
        outputs = vgg16(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        lr_sche.step()
    
        #print statistics
        running_loss += loss.item()
        if i % 30 == 29:
            loss_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader)]))
            print('[%d, %5d] loss: %.3f' %
                 (epoch + 1, i + 1, running_loss / 30))
            running_loss = 0.0
print('Finished Training')
```
```python
dataiter = iter(testloader)
images, labels = dataiter.next()

# print images
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
```
```python
outputs = vgg16(images.to(device))
```
```python
_, predicted = torch.max(outputs, 1)

print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]
                              for j in range(4)))
```
```python
correct = 0
total = 0

with torch.no_grad():
    for data in testloader:
        images, labels = data
        images = images.to(device)
        labels = labels.to(device)
        outputs = vgg16(images)
        
        _, predicted = torch.max(outputs.data, 1)
        
        total += labels.size(0)
        
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
```

### ë§ˆë¬´ë¦¬
VGG Netì—ì„œ Layerì˜ êµ¬ì„±ë°©ë²•ê³¼ ì–´ë–»ê²Œ í•™ìŠµí•˜ëŠ”ì§€ì— ëŒ€í•´ ë‹¤ë£¨ì–´ ë³´ì•˜ë‹¤.

ì´ë¯¸ ë‹¤ë¥¸ í¬ìŠ¤íŒ…ë“¤ì—ì„œ MNISTë¥¼ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ë‹¤ë£¨ë©´ì„œ í•™ìŠµ ì½”ë“œë¥¼ ë‹¤ë¤„ë³¸ ìƒíƒœì´ê¸°ì—  
ë°”ë€ ë¶€ë¶„ë§Œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì˜€ë‹¤.  

ì½”ë“œëŠ” ì´í•´ê°€ ì•ˆê°„ë‹¤ë©´ ê°•ì˜ì—ì„œ ë” ì˜ ì„¤ëª…í•´ì£¼ì‹œë‹ˆ ê·¸ê²ƒì„ ì°¸ê³ í•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ë‹¤.

### ì°¸ê³ ìë£Œ
[pytorch ë”¥ëŸ¬ë‹ ê°•ì˜](https://www.boostcourse.org/ai214/lecture/43769?isDesc=false)

ğŸ“£<br>
ë³¸ í¬ìŠ¤íŒ…ì˜ í•™ìŠµ í™˜ê²½ : `Anaconda`, `CPU`, `Pytorch`, `Jupyter Notebook`  
í¬ìŠ¤íŒ…ì—ì„œ ì˜¤ë¥˜ë‚˜ ê¶ê¸ˆí•œ ì ì€ Commentsë¥¼ ì‘ì„±í•´ì£¼ì‹œë©´, ë§ì€ ë„ì›€ì´ ë©ë‹ˆë‹¤.ğŸ’¡  
{: .notice--info}