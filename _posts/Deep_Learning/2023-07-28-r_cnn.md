---
title : "[논문 리뷰] Rich feature hierarchies for accurate object detection and semantic segmentation(R-CNN)"
category :
    - Deep_Learning_Study
tag :
    - Deep_Learning
toc : true
toc_sticky: true
comments: true
sidebar_main: true
---
[CVPR, 2014] Rich feature hierarchies for accurate object detection and semantic segmentation 논문 리뷰

# Introduction

# 2. Object detection with R-CNN

본 논문의 object detection 시스템은 세 개의 모듈로 구성되어있다.

**첫 번째 모듈**은 category-independent한 **region proposal**을 생성한다.

이 제안은 본 논문의 detector가 사용 가능한 detection 후보들의 집합을 정의한다.

**두 번째 모듈**은 large **convolution nerual network**로 각 region으로부터 고정된 길이의(fixed-length) feature vector를 추출한다.

**세 번째 모듈**은 clss-specific **linear SVM**의 집합이다.(분류 진행)

본 섹션에서는 각 모듈에 대해 design decision을 설명하고 테스트와 파라미터가 어떻게 학습되는지, 그리고 PASCAL VOC 2010-12에서의 결과를 보여준다.

## 2-1. Module design
### Region Proposal

이전 연구들에서 category-independent한 region proposal을 생성하는 방법을 다양하게 제시했다.

objectness, selective search, constrained parametric min-cuts (CPMC) 등등

R-CNN은 여러 방법들 중 이전 검출 작업들과 제어된 비교를 하기 위해 **selective search**를 사용한다.<br>
(Uijlings, Jasper RR, et al. "Selective search for object recognition." International journal of computer vision 104 (2013): 154-171.)

<p align="center"><img src="/MyPDF/rcnn(1).png" width = "700" ></p>
<p align="center"> selective search </p>

selective search는 다음 순서로 이루어진다.

**1:** "Efficient Graph Based Image Segmentation" 방법을 이용해 초기 영역을 지정한다.<br>위 그림에서 가장 왼쪽 사진이 이에 해당한다.<br>
<p align="center"><img src="/MyPDF/rcnn(2).png" width = "500" ></p><br>
(Felzenszwalb, Pedro F., and Daniel P. Huttenlocher. "Efficient graph-based image segmentation." International journal of computer vision 59 (2004): 167-181.)

**2:** 네모 박스끼리의 영역 유사도를 계산한다.<br>Greedy 알고리즘을 이용하여 유사도가 높은 영역끼리 합쳐짐을 반복한다. 서로 엉킨 구역이 signle region이 될 때까지 반복한다.<br>

**3:** 위 작업을 반복하여 2000개의 region proposal을 추출한다.

### Feature extraction
Krizhevsky 등이 설명한 CNN의 Caffe 구현을 사용하여 각 지역 제안으로부터 4096차원의 특징 벡터를 추출한다.

feature는 평균을 뺀 227 by 227 RGB 이미지를 5개의 convolution layer와 2개의 fully connected layer를 통해 forward propagation하며 계산한다.

region proposal에 대한 feature를 계산하려면 해당 region의 이미지 데이터를 CNN과 호환되는 형식으로 변환해야한다.(227 by 227 image)

본 논문은 가장 간단한 변환을 선택하였다.

candidate region의 크기나 종횡비에 상관없이 필요한 사이즈(227 by 227 image)로  warp(resize)하여 CNN에 입력한다.

wrap과정에서 object 주변에 16개의 픽셀도 포함하였다.

<p align="center"><img src="/MyPDF/rcnn(3).png" width = "700" ></p>

(Feature extraction 부분의 참고 문헌을 살펴보니 AlexNet이었다.<br>
Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Advances in neural information processing systems 25 (2012).)

## 2-2. Test-time detection
테스트 단계에서, 테스트 이미지에 대해 selective search를 실행하여 2000개의 region proposal을 추출한다.<br>
(모든 실험에서는 선택적 검색의 "빠른 모드"를 사용한다고 한다.)

각 proposal을 warp하고 CNN을 통해 forward propagate하여 layer의 feature를 추출한다.

이후 각 클래스에 대해 해상 클래스에 대해 훈련된 SVM을 사용하여 추출된 feature vector를 점수화한다.

이미지에서 모든 점수화된 영역이 주어지면 본 논문은 region을 reject하는 **greedy non-maximum suppression**를 적용한다.<br>
이 과정은 threshold 이하의 score를 가지는 bounding box는 제거하고,<br>
(이 과정은 따로 찾아본 것이고 논문에는 아래만 소개되어있는 것 같다.)
<br>

남은 bounding box들 중 가장 큰 것을 기준으로 잡고,<br>
**IoU**가 threshold 이상인 bounding box들은 제거한다. 이 과정을 통해 많이 겹쳐진 것은 같은 물체를 검출하고 있다는 것을 의미하고 이를 제거한다.

<p align="center"><img src="/MyPDF/rcnn(4).png" width = "500" ></p>

### Run-time analysis
두 가지 특성으로 인해 detection이 효율적으로 이루어진다.

- 모든 CNN 매개변수는 모든 category에 대해 공유된다.
- CNN에 의해 계산된 특징 벡터는 다른 일반적인 방식인 bag-of-visual-word 인코등을 사용한 spatial pyramids과 비교할 때 저차원이다.<br>
(예를 들어 UVA detection system에서 사용하는 특징은 본 논문의 특징보다 두 배 크다.)
- 그 결과 모든 클래스에 대해 객체 탐지를 수행하는 데 한 이미지당 GPU로는 13초, CPU로는 53초가 걸린다.

class-specific computation은 SVM 가중치와 feature 사이의 dot product와 non-maximum suppression뿐이다.

뒷 내용은 R-CNN이 효율적이고 다른 모델들에 비해 용량 및 런타임에서 좋은 모습을 보인다는 것을 설명한다.

## 2-3. Training
### Supervised pre-training
Bounding box label이 없는 이미지 수준의 annotation으로 사전 훈련시켰다. 대규모 보조 데이터셋(ILSVRC 2012)사용.

CNN 자체는 Krizhevsky의 성능과 거의 일치<br>
(Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Advances in neural information processing systems 25 (2012).)

### Domain-specific fine-tuning
CNN을 detection이라는 새로운 작업과 새로운 도메인 warped VOC windows에 적용시키기 위해,

오직 VOC에서 warped region proposal만을 이용해 CNN 파라미터를 갱신한다.

이때 SGD를 사용했다.

CNN의 ImageNet 특정 1000개 분류 레이어를 무작위로 초기화된 21개 분류 레이어(20개의 VOC 클래스와 배경)로 대체하는 것을 제외하면, CNN 아키텍처는 변경되지 않는다.

또한, ground truth box와 IoU 오버랩이 0.5 이상인 region proposal만 positive로 여기고, 나머지는 negative로 여긴다.

SGD는 학습률 0.001(초기 사전 훈련 속도의 1/10)에서 시작한다.<br>
이는 세밀 조정을 진행하면서 초기화를 파괴하지 않도록 한다.

각 SGD 반복에서 모든 클래스에 걸친 32개의 positive 윈도우와 96개의 background 윈도우를 균일하게 샘플링하여 크기가 128인 미니 배치를 구성한다.

positive window는 background에 비해 매우 드물기 때문에 sampling을 positive window를 향하도록 편향시킨다.

### Object category classifiers
자동차를 꽉 둘러싸고 있는 이미지 영역은 positive example로 명확하다.
 
마찬가지로 자동차와 관련이 없는 배경 영역은 negative example로 명확하다. 
 
그러나 자동차와 부분적으로 겹치는 영역을 어떻게 레이블링해야 할지는 덜 명확하다.

이 문제는 IoU(Intersection over Union) 오버랩 임계값으로 해결한다.

이 임계값 아래에서 영역은 negative로 정의된다.

IoU 임계값은 0.3이며 이는 validation set에서 0, 0.1, ..., 0.5로 실험해보며 선택되었다.

이 임계값 설정은 신중하게 선택하는 것이 중요하다고 소개한다.

만약 IoU 임계값을 0.5로 정하면 mAP가 5 포인트 떨어지며, 임계값을 0으로 설정하면 mAP가 4 포인트 떨어진다.

positive example은 각 클래스의 ground-truth bounding box로 간단히 정의된다.

특징이 추출되고 훈련 레이블이 적용되면,<br>
각 클래스당 하나의 선형 SVM을 최적화한다.

훈련 데이터가 메모리에 맞지 않을 정도로 크기 때문에, standard hard negative mining method를 채택하였다.

hard negative mining method는 빠르게 수렴하며 실제로 mAP는 모든 이미지를 한 번만 통과한 후 증가하지 않는다.

부록 자료에서 fine-tuning과 SVM 훈련에서 양성 및 음성 예시를 다르게 정의하는 이유에 대해 논의한다.<br>
(hard negative mining이란 positive 샘플과 negative 샘플의 개수를 균일하게 만드는 방법입니다. 신뢰도 점수(confidence score)를 활용해 negative 샘플을 선정하는 것)

(negative는 배경)

<p align="center"><img src="/MyPDF/rcnn(10).png" width = "600" ></p>

<p align="center"><img src="/MyPDF/rcnn(11).png" width = "700" ></p>

## 2.4 Result on PASCAL VOC 2010-12
<p align="center"><img src="/MyPDF/rcnn(5).png" width = "700" ></p>

# 3. Visualization, ablation, and modes of error
## 3.1 Visualizing learned features
첫 번째 layer filter는 시각화할 수 있으며 이해하기 쉽다.

이 필터들은 방향성 있는 가장자리(oriented edges)와 반대 색(opponent color)를 포착한다.<br>
(경계와 보색)

그러나 다음 레이어를 이해하는 것이 어렵다.

본 논문은 간단하고 보완적인 non-parametric 방법을 제안한다. 이 방법은 네트워크가 배운 내용을 직접적으로 보여준다.

아이디어는 네트워크 내에서 특정 유닛(feature)을 개별적으로 추출하고 마치 독립적인 객체 탐지기처럼 사용하는 것이다.

즉, 대량의 region proposal(약 1000만 개)에 대해 해당 유닛의 활성화(unit's activation)를 계산하고, 활성화가 높은 순서대로 제안들을 정렬한다.

이후 non-maximum suppression를 수행하여 상위 점수의 지역을 표시한다.

이 방법은 선택한 유닛이 "자체적으로 말하도록"하여 정확히 어떤 입력에서 활성화되는지를 보여준다.

이는 다른 visual mode를 보기 위해 평균화를 피하고 unit에 의해 계산된 invariance에 대한 통착력을 얻는다.

네트워크의 다섯 번째 및 마지막 컨볼루션 레이어의 출력인 pool5 레이어의 유닛들을 시각화한다.
(pool5 피처 맵은 6 × 6 × 256 = 9216 차원)

경계 효과(boundary effects)를 무시하면, 각 pool5 유닛은 원본 227 × 227 픽셀 입력에서 195 × 195 픽셀의 수용 영역(receptive field)을 가진다.

중앙의 pool5 유닛은 거의 전역적인 시야를 가지며, 가장자리에 있는 유닛은 더 작고 자른 지원 영역을 가지게 된다.

<p align="center"><img src="/MyPDF/rcnn(6).png" width = "700" ></p>

<p align="center"><img src="/MyPDF/rcnn(7).png" width = "700" ></p>

이 네트워크는 클래스에 특화된 몇 개의 기능들을 결합한 표현과 동시에 형태, 질감, 색상 및 소재 특성에 대한 분산 표현을 학습한다.

## 3.2 Ablation studies
### Performance layer-by-layer, without fine-tuning
detection performance에 있어서 어떤 레이어들이 중요한지 이해하기 위해, VOC 2007 데이터셋에서 CNN의 마지막 세 개 레이어에 대한 결과를 분석했다.

마지막 두 개의 레이어는 다음과 같다.

Layer fc6 is fully connected to pool5<br>
이 레이어는 4096x9216 크기의 가중치 행렬을 pool5 피처 맵(9216 차원 벡터로 재구성)과 곱한 후 벡터 형태의 편향(bias)을 더한다.

이 중간 벡터는 각 요소에 half-wave rectified를 적용한다.
$ (max(0,x) \to x)$

레이어 fc7은 네트워크의 마지막 레이어이다.

이 레이어는 fc6에서 계산된 피처를 4096x4096 크기의 가중치 행렬과 곱한 후 벡터 형태의 편향을 더하고, half-wave rectified를 적용한다.

<p align="center"><img src="/MyPDF/rcnn(8).png" width = "700" ></p>

먼저, PASCAL에서 미세 조정되지 않은 CNN의 결과를 살펴본다.

모든 CNN 파라미터가 오직 ILSVRC 2012에서 미리 학습되었다.

레이어별 성능 분석 (Table 2의 1-3행)은 fc7의 피처가 fc6의 피처보다 일반화 성능이 더 낮다는 것을 보여준다.

이는 CNN의 파라미터 중 29%, 약 1680만 개 정도가 제거되어도 mAP를 저하시키지 않을 수 있다는 것을 의미한다.

놀라운 사실은 fc7과 fc6을 모두 제거해도 꽤 좋은 결과를 얻을 수 있다는 것이다.

pool5 피처는 CNN의 파라미터 중 단 6%만을 사용하여 계산되지만, CNN의 표현력의 많은 부분은 컨볼루션 레이어에서 비롯되는 것을 의미한다(밀집하게 연결된 레이어에 비해)

이러한 발견은 CNN의 컨볼루션 레이어만 사용하여 임의 크기의 이미지의 밀집 피처 맵을 계산하는 것, 즉 HOG(Histogram of Oriented Gradients)와 같은 밀집 피처 맵을 계산하는 것이 가능하다는 것을 시사한다고 한다.<br>
( 이러한 표현 방식은 pool5 피처 위에 슬라이딩 윈도우 검출기, DPM(Discriminative Part-Based Model) 등을 실험해 볼 수 있게 한다)

<p align="center"><img src="/MyPDF/rcnn(9).png" width = "700" ></p>

(mAP는 Mean Avearage Precision의 약자.)<br>
([mAP:Mean-Average-Precision-정리 블로그 참고](https://ctkim.tistory.com/entry/mAPMean-Average-Precision-%EC%A0%95%EB%A6%AC))에서 참고.


### Performance layer-by-layer, with fine-tuning
VOC 2007 trainval 데이터셋으로 CNN의 파라미터를 미세 조정한 후의 결과를 살펴본다.

개선이 두드러진다(Table 2의 4-6행)<br>
미세 조정으로 mAP가 8.0 퍼센트 포인트 증가하여 54.2%가 된다.

미세 조정으로 인한 향상은 pool5보다는 **fc6와 fc7에서 훨씬 크다**.

이는 ImageNet에서 학습한 **pool5 피처들이 일반적**이며, 대부분의 향상은 이러한 피처들 위에 domain-specific non-linear classifiers를 학습함으로써 얻어진 것으로 보인다.

### Comparison to recent feature learning methods
모든 R-CNN의 변형이 세 가지 DPM보다 뛰어난 결과를 보인다.

## 3.3 Detection error analysis
분석 도구의 전체 요약은 이 논문의 범위를 벗어나며, 세부 사항을 이해하려면 관련 reference확인

## 3.4. Bounding box regression
DPM에서 사용되는 경계 상자 회귀(bounding box regression)에서 영감을 받아, pool5 피처를 사용하여 선택적 탐색(region proposal) 영역에 대한 새로운 검출 윈도우를 예측하기 위해 선형 회귀 모델을 훈련시켰다.

이 간단한 방법 BB(Bounding box)가 적용된 방법인 잘못된 위치로 탐지된 검출들을 많이 수정하여 mAP를 3에서 4포인트로 증가시키는 것을 보인다.

---

selective search 알고리즘을 통해 얻은 객체의 위치는 부정확할 수 있다. 이런 문제를 해결하기 위해 객체의 위치를 조절해주는 Bounding box regressor가 있다.

<p align="center"><img src="/MyPDF/rcnn(12).png" width = "500" ></p>

# 4. Semantic Segmentation
영역 classification은 semantic segmentation의 표준 기술로, R-CNN을 PASCAL VOC 세그멘테이션 챌린지에 쉽게 적용할 수 있었다.

좋은 결과를 보였다.

# 5. Conclusion
본 논문은 간단하고 확장 가능한 객체 탐지 알고리즘을 제안합니다. 이 알고리즘은 PASCAL VOC 2012에서 최고 성능의 이전 결과에 비해 상대적으로 30%의 성능 향상을 보여준다.

이러한 성능을 두 가지 통찰력으로 달성했습니다. 첫 번째는 고용량 컨볼루션 신경망을 하향식(region proposals) 영역 제안에 적용하여 객체를 지역화하고 분할하는 것이다.

두 번째는 라벨이 있는 훈련 데이터가 희귀한 경우 대규모 CNN을 훈련하기 위한 패러다임이다.

네트워크를 미리 교육하고, 그 후에 희소한 데이터(객체 탐지)에 대해 네트워크를 미세 조정하는 것이 매우 효과적이라는 것을 보인다.

"supervised pre-training/domain-specific finetuning" 패러다임이 다양한 데이터 희귀한 비전 문제에 대해 매우 효과적일 것으로 추정한다.